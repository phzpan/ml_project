{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIMH Project - Machine Learning - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import math\n",
    "import chardet\n",
    "os.chdir('C:/Users/hpan/Documents/python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip following goto start, load pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>pat_visit</th>\n",
       "      <th>r_score</th>\n",
       "      <th>sum1</th>\n",
       "      <th>fsize</th>\n",
       "      <th>note_txt</th>\n",
       "      <th>labelm</th>\n",
       "      <th>labeln</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>19251156_2244945</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>MRN:                     19251156\\r\\r\\n...... ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>5648753_185153195</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>MRN: 5648753\\r\\r\\n...... MRN: 5648753\\r\\r\\n......</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>257</td>\n",
       "      <td>6461602_183586354</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>MRN:           6461602\\r\\r\\n...... MRN:       ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>412</td>\n",
       "      <td>8538647_2092146</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>MRN:     8538647\\r\\r\\n...... MRN:             ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>434</td>\n",
       "      <td>6285951_2295095</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>43</td>\n",
       "      <td>MRN:     6285951\\r\\r\\n...... MRN:             ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1          pat_visit  r_score  sum1  fsize  \\\n",
       "0           0             9   19251156_2244945        7     1     13   \n",
       "1           1           270  5648753_185153195       11    13     23   \n",
       "2           2           257  6461602_183586354       12    12     24   \n",
       "3           3           412    8538647_2092146       13    18     16   \n",
       "4           4           434    6285951_2295095       13    20     43   \n",
       "\n",
       "                                            note_txt  labelm  labeln  \n",
       "0  MRN:                     19251156\\r\\r\\n...... ...       0       0  \n",
       "1  MRN: 5648753\\r\\r\\n...... MRN: 5648753\\r\\r\\n......       1       1  \n",
       "2  MRN:           6461602\\r\\r\\n...... MRN:       ...       1       1  \n",
       "3  MRN:     8538647\\r\\r\\n...... MRN:             ...       1       1  \n",
       "4  MRN:     6285951\\r\\r\\n...... MRN:             ...       1       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "data = pd.read_csv(\"./results/tt_4801395.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "corpusList=data[data.columns[6]].tolist()\n",
    "labelm=data[data.columns[7]].tolist()\n",
    "labeln=data[data.columns[8]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpusList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#%%\n",
    "#test\n",
    "os.chdir('C:/Users/hpan/Documents/python')\n",
    "test = pd.read_csv(\"./results/test_800595.csv\")\n",
    "\n",
    "#%%\n",
    "corpusList_test=test[train.columns[5]].tolist()\n",
    "labels_testm=test[train.columns[6]].tolist()\n",
    "labels_testn=test[train.columns[7]].tolist()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def tokenize(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = [ token for token in tokens if re.search('(^[a-zA-Z]+$)', token) ]\n",
    "    a=[]\n",
    "    for i in filtered_tokens:\n",
    "        a.append(WordNetLemmatizer().lemmatize(i,'v'))\n",
    "    return a\n",
    "    #return filtered_tokens\n",
    "\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1875, 2054755)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "cv = TfidfVectorizer(lowercase=True,\n",
    "                     ngram_range=(1, 4), preprocessor=None, stop_words='english',\n",
    "                     strip_accents=None, tokenizer=tokenize, vocabulary=None)\n",
    "X1 = cv.fit_transform(corpusList)\n",
    "lexicon = cv.get_feature_names()\n",
    "#print (lexicon)\n",
    "print()\n",
    "\n",
    "#%%\n",
    "x=X1  ## for select fetures \n",
    "print(x.shape)\n",
    "\n",
    "pkl.dump( x, open( \"./results/tfidf_4801395.pickle\", \"wb\" ) )\n",
    "pkl.dump( lexicon, open( \"./results/lexicon_4801395.pickle\", \"wb\" ) )\n",
    "#x1 = pkl.load( open( \"./results/tfidf_4801395.pickle\", \"rb\" ) )\n",
    "#lexicon1 = pkl.load( open( \"./results/lexicon_4801395.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ym = np.array(labelm)\n",
    "Yn = np.array(labeln)\n",
    "pkl.dump( Ym, open( \"./results/ym_4801395.pickle\", \"wb\" ) )\n",
    "pkl.dump( Yn, open( \"./results/yn_4801395.pickle\", \"wb\" ) )\n",
    "#print(Y)  ## class level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#%%\n",
    "#test\n",
    "cvt = TfidfVectorizer(lowercase=True,\n",
    "                     ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
    "                     strip_accents=None, tokenizer=tokenize, vocabulary=None)\n",
    "\n",
    "X1t = cvt.fit_transform(corpusList_test)\n",
    "print(X1t.shape)\n",
    "print()\n",
    "lexicon_test = cvt.get_feature_names()\n",
    "#print (lexicon)\n",
    "print()\n",
    "\n",
    "#%%\n",
    "xt=X1t  ## for select fetures \n",
    "print(xt.shape)\n",
    "\n",
    "Ym = np.array(labels_testm)\n",
    "Yn = np.array(labels_testn)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 0 1 1] [1 1 1 0 0 0 0 0 0 0] [1 0 1 0 0 1 0 0 0 1]\n",
      "[0 1 1 1 1 1 1 0 1 1] [1 0 0 0 1 1 0 0 1 1] [0 0 0 0 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(Ym[0:10], Ym[480:490], Ym[1865:])  ## class level\n",
    "print(Yn[0:10], Yn[480:490], Yn[1865:])  ## class level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1875, 800)\n"
     ]
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=800).fit_transform(x, Yn)   # select 800 features\n",
    "\n",
    "#%%\n",
    "X=X_new        # make unque name for next cell \n",
    "print(X.shape)\n",
    "#Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump( X, open( \"./results/tfidf_4801395_chi2_800.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5328"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = pkl.load( open( \"./results/tfidf_4801395_chi2_800.pickle\", \"rb\" ) )\n",
    "Ym = pkl.load( open( \"./results/ym_4801395.pickle\", \"rb\" ) )\n",
    "Yn = pkl.load( open( \"./results/yn_4801395.pickle\", \"rb\" ) )\n",
    "nlp_acc = sum(Ym==Yn)/len(Ym)\n",
    "print(nlp_acc)\n",
    "nlp_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse.csr.csr_matrix, numpy.ndarray, 1875)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_new), type(Yn), len(Ym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_new[:960]\n",
    "X2 = X_new[960:]\n",
    "Yn1 = Yn[:960]\n",
    "Yn2 = Yn[960:]\n",
    "Y = Ym[:960]\n",
    "Y2 = Ym[960:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1395, 600)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"X2_new = SelectKBest(chi2, k=600).fit_transform(xt, Ym)   # select 600 features\n",
    "X2_new.shape\n",
    "\n",
    "#%%\n",
    "X2=X2_new        # make unque name for next cell \n",
    "X2_new.shape\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  0 : ExtraTreesClassifier = 10\n",
      "   Fold 1 accuracy: 61.46 %\n",
      "   Fold 2 accuracy: 62.50 %\n",
      "   Fold 3 accuracy: 64.58 %\n",
      "   Fold 4 accuracy: 77.08 %\n",
      "   Fold 5 accuracy: 69.79 %\n",
      "   Fold 6 accuracy: 69.79 %\n",
      "   Fold 7 accuracy: 63.54 %\n",
      "   Fold 8 accuracy: 69.79 %\n",
      "   Fold 9 accuracy: 66.67 %\n",
      "   Fold 10 accuracy: 68.75 %\n",
      "     Overall test accuracy: 67.40 %\n",
      "     Overall training accuracy: 98.33 %\n",
      "model  1 : ExtraTreesClassifier = 30\n",
      "   Fold 1 accuracy: 72.92 %\n",
      "   Fold 2 accuracy: 64.58 %\n",
      "   Fold 3 accuracy: 71.88 %\n",
      "   Fold 4 accuracy: 66.67 %\n",
      "   Fold 5 accuracy: 64.58 %\n",
      "   Fold 6 accuracy: 65.62 %\n",
      "   Fold 7 accuracy: 63.54 %\n",
      "   Fold 8 accuracy: 68.75 %\n",
      "   Fold 9 accuracy: 73.96 %\n",
      "   Fold 10 accuracy: 72.92 %\n",
      "     Overall test accuracy: 68.54 %\n",
      "     Overall training accuracy: 99.48 %\n",
      "model  2 : ExtraTreesClassifier = 60\n",
      "   Fold 1 accuracy: 78.12 %\n",
      "   Fold 2 accuracy: 61.46 %\n",
      "   Fold 3 accuracy: 69.79 %\n",
      "   Fold 4 accuracy: 62.50 %\n",
      "   Fold 5 accuracy: 70.83 %\n",
      "   Fold 6 accuracy: 68.75 %\n",
      "   Fold 7 accuracy: 66.67 %\n",
      "   Fold 8 accuracy: 70.83 %\n",
      "   Fold 9 accuracy: 75.00 %\n",
      "   Fold 10 accuracy: 65.62 %\n",
      "     Overall test accuracy: 68.96 %\n",
      "     Overall training accuracy: 98.96 %\n",
      "model  3 : ExtraTreesClassifier = 100\n",
      "   Fold 1 accuracy: 71.88 %\n",
      "   Fold 2 accuracy: 70.83 %\n",
      "   Fold 3 accuracy: 65.62 %\n",
      "   Fold 4 accuracy: 70.83 %\n",
      "   Fold 5 accuracy: 73.96 %\n",
      "   Fold 6 accuracy: 72.92 %\n",
      "   Fold 7 accuracy: 69.79 %\n",
      "   Fold 8 accuracy: 68.75 %\n",
      "   Fold 9 accuracy: 66.67 %\n",
      "   Fold 10 accuracy: 71.88 %\n",
      "     Overall test accuracy: 70.31 %\n",
      "     Overall training accuracy: 99.38 %\n",
      "model  4 : ExtraTreesClassifier = 300\n",
      "   Fold 1 accuracy: 69.79 %\n",
      "   Fold 2 accuracy: 68.75 %\n",
      "   Fold 3 accuracy: 72.92 %\n",
      "   Fold 4 accuracy: 68.75 %\n",
      "   Fold 5 accuracy: 71.88 %\n",
      "   Fold 6 accuracy: 65.62 %\n",
      "   Fold 7 accuracy: 72.92 %\n",
      "   Fold 8 accuracy: 63.54 %\n",
      "   Fold 9 accuracy: 75.00 %\n",
      "   Fold 10 accuracy: 62.50 %\n",
      "     Overall test accuracy: 69.17 %\n",
      "     Overall training accuracy: 99.38 %\n",
      "model  5 : ExtraTreesClassifier = 500\n",
      "   Fold 1 accuracy: 65.62 %\n",
      "   Fold 2 accuracy: 69.79 %\n",
      "   Fold 3 accuracy: 72.92 %\n",
      "   Fold 4 accuracy: 65.62 %\n",
      "   Fold 5 accuracy: 71.88 %\n",
      "   Fold 6 accuracy: 76.04 %\n",
      "   Fold 7 accuracy: 66.67 %\n",
      "   Fold 8 accuracy: 76.04 %\n",
      "   Fold 9 accuracy: 67.71 %\n",
      "   Fold 10 accuracy: 66.67 %\n",
      "     Overall test accuracy: 69.90 %\n",
      "     Overall training accuracy: 99.48 %\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# ExtraTreesClassifier\n",
    "model=0\n",
    "results = []\n",
    "cont = []\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "trees = [10, 30, 60, 100, 300, 500]\n",
    "for t in range(len(trees)):\n",
    "    fold = 1\n",
    "    truth = []\n",
    "    rf_prediction = []\n",
    "    print(\"model \", t, \": ExtraTreesClassifier = \" + str(trees[t]))\n",
    "    test_count = 0\n",
    "    rf = ExtraTreesClassifier(bootstrap=False,\n",
    "           criterion='entropy', max_depth=15, max_features=0.9,\n",
    "           max_leaf_nodes=None, min_impurity_decrease=1e-045,\n",
    "           min_samples_leaf=1, min_samples_split=3,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=trees[t], n_jobs=-1,\n",
    "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        trainX = X[train_idx]\n",
    "        trainY = Y[train_idx]\n",
    "        testX = X[test_idx]\n",
    "        testY = Y[test_idx]\n",
    "        truth.append(testY)\n",
    "        rf.fit(trainX, trainY)\n",
    "        Y_hat = rf.predict(testX)\n",
    "        rf_prediction.append(Y_hat)\n",
    "        print(\"   Fold %d accuracy: %.2f %%\" % (fold, ((np.sum(Y_hat == testY)/len(testY)) * 100.0)))                        \n",
    "        fold += 1\n",
    "    truth = np.concatenate(truth, axis=0)    \n",
    "    rf_prediction = np.concatenate(rf_prediction, axis=0)\n",
    "    test_results = np.sum(rf_prediction == truth)/len(truth)\n",
    "    print(\"     Overall test accuracy: %.2f %%\" % (test_results * 100))  \n",
    "    rf = rf.fit(X, Y)\n",
    "    Y_hat = rf.predict(X)\n",
    "    train_results = np.sum(Y_hat == Y)/len(Y)\n",
    "    print(\"     Overall training accuracy: %.2f %%\" % (train_results * 100.0))  \n",
    "    results.append([train_results, test_results])   \n",
    "    cont.append([truth, rf_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ExtraTreesClassifier(bootstrap=False,\n",
    "       criterion='entropy', max_depth=15, max_features=0.9,\n",
    "       max_leaf_nodes=None, min_impurity_decrease=1e-045,\n",
    "       min_samples_leaf=1, min_samples_split=3,\n",
    "       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,      #trees[t] = 100\n",
    "       oob_score=False, random_state=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385\n",
      "vm  0.5486338797814208\n",
      "vn  0.6240437158469946\n",
      "388\n",
      "vm  0.5409836065573771\n",
      "vn  0.6120218579234973\n",
      "379\n",
      "vm  0.5442622950819672\n",
      "vn  0.6415300546448087\n",
      "381\n",
      "vm  0.5508196721311476\n",
      "vn  0.6109289617486339\n",
      "384\n",
      "vm  0.5387978142076503\n",
      "vn  0.6207650273224044\n",
      "nlp\n",
      "precision:  0.4557291666666667\n",
      "recall:  0.45103092783505155\n",
      "F1:  0.4533678756476684\n",
      "nlp0\n",
      "precision:  0.5988700564971752\n",
      "recall:  0.603415559772296\n",
      "F1:  0.4533678756476684\n",
      "ave\n",
      "precision:  0.527299611581921\n",
      "recall:  0.5272232438036738\n",
      "F1:  0.4533678756476684\n"
     ]
    }
   ],
   "source": [
    "train_num = 5\n",
    "for i in range(train_num):\n",
    "    rf.fit(X, Y)\n",
    "    Y2_hat = rf.predict(X2)\n",
    "    vn = np.sum(Y2_hat == Yn2)/len(Yn2)\n",
    "    vm = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "    print(np.sum(Y2_hat))\n",
    "    print(\"vm \", vm)\n",
    "    print(\"vn \",vn)\n",
    "    \n",
    "precision = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2)-np.sum(Y2))\n",
    "f10 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp0\")\n",
    "print(\"precision: \", precision0)\n",
    "print(\"recall: \", recall0)\n",
    "print(\"F1: \", f10)\n",
    "\n",
    "print(\"ave\")\n",
    "print(\"precision: \", (precision+precision0)/2)\n",
    "print(\"recall: \", (recall+recall0)/2)\n",
    "print(\"F1: \", (f1+f10)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(915, 800)\n",
      "915\n"
     ]
    }
   ],
   "source": [
    "print(X2.shape)\n",
    "print(len(Y2_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Best Model: 3\n",
      "\n",
      "ExtraTrees\n",
      "         no  social  Total\n",
      "no      378     155    533\n",
      "social  130     297    427\n",
      "Total   508     452    960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "model = input(\"Enter Best Model: \")\n",
    "best = cont[int(model)]\n",
    "rf_ct = pd.crosstab(best[1], best[0], margins=True)\n",
    "rf_ct.columns = [\"no\", \"social\", \"Total\"]\n",
    "rf_ct.index = [\"no\", \"social\", \"Total\"]\n",
    "print()\n",
    "print(\"ExtraTrees\")\n",
    "print(rf_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[378 130]\n",
      " [155 297]]\n",
      "0.6757679180887372\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,classification_report\n",
    "y_true =cont[int(model)][0]\n",
    "y_pred = cont[int(model)][1]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6570796460176991\n",
      "0.6955503512880562\n",
      "0.703125\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.74      0.73       508\n",
      "          1       0.70      0.66      0.68       452\n",
      "\n",
      "avg / total       0.70      0.70      0.70       960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_true, y_pred),   )\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees: Sensitivity: 0.65708 Specificity: 0.74409 PPV: 0.69555 NPV: 0.70919 Accuracy: 0.70312\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "Sens = rf_ct.iloc[1][1]/rf_ct.iloc[2][1]\n",
    "Spec = rf_ct.iloc[0][0]/rf_ct.iloc[2][0]\n",
    "PPV = rf_ct.iloc[1][1]/rf_ct.iloc[1][2]\n",
    "NPV = rf_ct.iloc[0][0]/rf_ct.iloc[0][2]\n",
    "ACC = (rf_ct.iloc[0][0] + rf_ct.iloc[1][1]) / rf_ct.iloc[2][2]\n",
    "print(\"ExtraTrees: Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  0.7005870671033377\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(best[0], best[1], pos_label=1)\n",
    "roc_auc = auc(rf_fpr, rf_tpr)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(rf_fpr, rf_tpr, label='ExtraTrees')\n",
    "plt.xlabel('False positive rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(\"AUC = \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0: SVM RBF Gamma=1.000 C=1.00\n",
      "   Fold 1 accuracy: 61.46 %\n",
      "   Fold 2 accuracy: 69.79 %\n",
      "   Fold 3 accuracy: 58.33 %\n",
      "   Fold 4 accuracy: 58.33 %\n",
      "   Fold 5 accuracy: 65.62 %\n",
      "   Fold 6 accuracy: 60.42 %\n",
      "   Fold 7 accuracy: 57.29 %\n",
      "   Fold 8 accuracy: 60.42 %\n",
      "   Fold 9 accuracy: 61.46 %\n",
      "   Fold 10 accuracy: 56.25 %\n",
      "     Overall test accuracy: 60.94 %\n",
      "     Overall training accuracy: 63.65 %\n",
      "model 1: SVM RBF Gamma=1.000 C=2.00\n",
      "   Fold 1 accuracy: 61.46 %\n",
      "   Fold 2 accuracy: 60.42 %\n",
      "   Fold 3 accuracy: 61.46 %\n",
      "   Fold 4 accuracy: 71.88 %\n",
      "   Fold 5 accuracy: 62.50 %\n",
      "   Fold 6 accuracy: 69.79 %\n",
      "   Fold 7 accuracy: 64.58 %\n",
      "   Fold 8 accuracy: 60.42 %\n",
      "   Fold 9 accuracy: 66.67 %\n",
      "   Fold 10 accuracy: 59.38 %\n",
      "     Overall test accuracy: 63.85 %\n",
      "     Overall training accuracy: 66.46 %\n",
      "model 2: SVM RBF Gamma=1.000 C=4.00\n",
      "   Fold 1 accuracy: 64.58 %\n",
      "   Fold 2 accuracy: 76.04 %\n",
      "   Fold 3 accuracy: 56.25 %\n",
      "   Fold 4 accuracy: 63.54 %\n",
      "   Fold 5 accuracy: 65.62 %\n",
      "   Fold 6 accuracy: 67.71 %\n",
      "   Fold 7 accuracy: 69.79 %\n",
      "   Fold 8 accuracy: 64.58 %\n",
      "   Fold 9 accuracy: 62.50 %\n",
      "   Fold 10 accuracy: 70.83 %\n",
      "     Overall test accuracy: 66.15 %\n",
      "     Overall training accuracy: 69.79 %\n",
      "model 3: SVM RBF Gamma=1.000 C=6.00\n",
      "   Fold 1 accuracy: 70.83 %\n",
      "   Fold 2 accuracy: 70.83 %\n",
      "   Fold 3 accuracy: 68.75 %\n",
      "   Fold 4 accuracy: 60.42 %\n",
      "   Fold 5 accuracy: 67.71 %\n",
      "   Fold 6 accuracy: 65.62 %\n",
      "   Fold 7 accuracy: 61.46 %\n",
      "   Fold 8 accuracy: 58.33 %\n",
      "   Fold 9 accuracy: 70.83 %\n",
      "   Fold 10 accuracy: 72.92 %\n",
      "     Overall test accuracy: 66.77 %\n",
      "     Overall training accuracy: 72.29 %\n",
      "model 4: SVM RBF Gamma=1.000 C=8.00\n",
      "   Fold 1 accuracy: 75.00 %\n",
      "   Fold 2 accuracy: 67.71 %\n",
      "   Fold 3 accuracy: 67.71 %\n",
      "   Fold 4 accuracy: 65.62 %\n",
      "   Fold 5 accuracy: 64.58 %\n",
      "   Fold 6 accuracy: 63.54 %\n",
      "   Fold 7 accuracy: 76.04 %\n",
      "   Fold 8 accuracy: 69.79 %\n",
      "   Fold 9 accuracy: 63.54 %\n",
      "   Fold 10 accuracy: 69.79 %\n",
      "     Overall test accuracy: 68.33 %\n",
      "     Overall training accuracy: 73.23 %\n",
      "model 5: SVM RBF Gamma=1.000 C=10.00\n",
      "   Fold 1 accuracy: 77.08 %\n",
      "   Fold 2 accuracy: 73.96 %\n",
      "   Fold 3 accuracy: 53.12 %\n",
      "   Fold 4 accuracy: 62.50 %\n",
      "   Fold 5 accuracy: 66.67 %\n",
      "   Fold 6 accuracy: 66.67 %\n",
      "   Fold 7 accuracy: 66.67 %\n",
      "   Fold 8 accuracy: 66.67 %\n",
      "   Fold 9 accuracy: 68.75 %\n",
      "   Fold 10 accuracy: 70.83 %\n",
      "     Overall test accuracy: 67.29 %\n",
      "     Overall training accuracy: 74.79 %\n",
      "model 6: SVM RBF Gamma=2.000 C=1.00\n",
      "   Fold 1 accuracy: 56.25 %\n",
      "   Fold 2 accuracy: 65.62 %\n",
      "   Fold 3 accuracy: 58.33 %\n",
      "   Fold 4 accuracy: 67.71 %\n",
      "   Fold 5 accuracy: 67.71 %\n",
      "   Fold 6 accuracy: 65.62 %\n",
      "   Fold 7 accuracy: 64.58 %\n",
      "   Fold 8 accuracy: 65.62 %\n",
      "   Fold 9 accuracy: 60.42 %\n",
      "   Fold 10 accuracy: 67.71 %\n",
      "     Overall test accuracy: 63.96 %\n",
      "     Overall training accuracy: 66.67 %\n",
      "model 7: SVM RBF Gamma=2.000 C=2.00\n",
      "   Fold 1 accuracy: 72.92 %\n",
      "   Fold 2 accuracy: 62.50 %\n",
      "   Fold 3 accuracy: 73.96 %\n",
      "   Fold 4 accuracy: 56.25 %\n",
      "   Fold 5 accuracy: 63.54 %\n",
      "   Fold 6 accuracy: 66.67 %\n",
      "   Fold 7 accuracy: 69.79 %\n",
      "   Fold 8 accuracy: 64.58 %\n",
      "   Fold 9 accuracy: 67.71 %\n",
      "   Fold 10 accuracy: 65.62 %\n",
      "     Overall test accuracy: 66.35 %\n",
      "     Overall training accuracy: 70.21 %\n",
      "model 8: SVM RBF Gamma=2.000 C=4.00\n",
      "   Fold 1 accuracy: 61.46 %\n",
      "   Fold 2 accuracy: 59.38 %\n",
      "   Fold 3 accuracy: 63.54 %\n",
      "   Fold 4 accuracy: 65.62 %\n",
      "   Fold 5 accuracy: 64.58 %\n",
      "   Fold 6 accuracy: 67.71 %\n",
      "   Fold 7 accuracy: 68.75 %\n",
      "   Fold 8 accuracy: 72.92 %\n",
      "   Fold 9 accuracy: 80.21 %\n",
      "   Fold 10 accuracy: 70.83 %\n",
      "     Overall test accuracy: 67.50 %\n",
      "     Overall training accuracy: 73.75 %\n",
      "model 9: SVM RBF Gamma=2.000 C=6.00\n",
      "   Fold 1 accuracy: 72.92 %\n",
      "   Fold 2 accuracy: 61.46 %\n",
      "   Fold 3 accuracy: 77.08 %\n",
      "   Fold 4 accuracy: 64.58 %\n",
      "   Fold 5 accuracy: 68.75 %\n",
      "   Fold 6 accuracy: 70.83 %\n",
      "   Fold 7 accuracy: 65.62 %\n",
      "   Fold 8 accuracy: 69.79 %\n",
      "   Fold 9 accuracy: 78.12 %\n",
      "   Fold 10 accuracy: 67.71 %\n",
      "     Overall test accuracy: 69.69 %\n",
      "     Overall training accuracy: 76.77 %\n",
      "model 10: SVM RBF Gamma=2.000 C=8.00\n",
      "   Fold 1 accuracy: 64.58 %\n",
      "   Fold 2 accuracy: 73.96 %\n",
      "   Fold 3 accuracy: 66.67 %\n",
      "   Fold 4 accuracy: 69.79 %\n",
      "   Fold 5 accuracy: 76.04 %\n",
      "   Fold 6 accuracy: 66.67 %\n",
      "   Fold 7 accuracy: 75.00 %\n",
      "   Fold 8 accuracy: 66.67 %\n",
      "   Fold 9 accuracy: 64.58 %\n",
      "   Fold 10 accuracy: 62.50 %\n",
      "     Overall test accuracy: 68.65 %\n",
      "     Overall training accuracy: 78.54 %\n",
      "model 11: SVM RBF Gamma=2.000 C=10.00\n",
      "   Fold 1 accuracy: 67.71 %\n",
      "   Fold 2 accuracy: 71.88 %\n",
      "   Fold 3 accuracy: 73.96 %\n",
      "   Fold 4 accuracy: 62.50 %\n",
      "   Fold 5 accuracy: 65.62 %\n",
      "   Fold 6 accuracy: 71.88 %\n",
      "   Fold 7 accuracy: 67.71 %\n",
      "   Fold 8 accuracy: 72.92 %\n",
      "   Fold 9 accuracy: 72.92 %\n",
      "   Fold 10 accuracy: 73.96 %\n",
      "     Overall test accuracy: 70.10 %\n",
      "     Overall training accuracy: 79.90 %\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# SVM\n",
    "model = 0\n",
    "cont = []\n",
    "results = pd.DataFrame(columns=('name', 'accuracy'))\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "C = [1,2,4,6,8,10]\n",
    "gamma = [1,2]  \n",
    "for g in range(len(gamma)):\n",
    "    acc = []\n",
    "    name = \"SVM RBF Gamma=%.3f\" % (gamma[g])     \n",
    "    for c in range(len(C)):\n",
    "        fold = 1\n",
    "        truth = []\n",
    "        svm_prediction = []\n",
    "        print(\"model %d: SVM RBF Gamma=%.3f C=%.2f\" % (model, gamma[g], C[c]))        \n",
    "        test_count = 0\n",
    "        svm = SVC(C=C[c], kernel='rbf', gamma=gamma[g])\n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            trainX = X[train_idx]\n",
    "            trainY = Y[train_idx]\n",
    "            testX = X[test_idx]\n",
    "            testY = Y[test_idx]\n",
    "            truth.append(testY)\n",
    "            svm.fit(trainX, trainY)\n",
    "            Y_hat = svm.predict(testX)\n",
    "            svm_prediction.append(Y_hat)\n",
    "            print(\"   Fold %d accuracy: %.2f %%\" % (fold, ((np.sum(Y_hat == testY)/len(testY)) * 100.0)))                        \n",
    "            fold += 1\n",
    "        truth = np.concatenate(truth, axis=0)    \n",
    "        svm_prediction = np.concatenate(svm_prediction, axis=0)\n",
    "        test_results = np.sum(svm_prediction == truth)/len(truth)\n",
    "        print(\"     Overall test accuracy: %.2f %%\" % (test_results * 100))  \n",
    "        svm = svm.fit(X, Y)\n",
    "        Y_hat = svm.predict(X)\n",
    "        train_results = np.sum(Y_hat == Y)/len(Y)\n",
    "        print(\"     Overall training accuracy: %.2f %%\" % (train_results * 100.0))  \n",
    "        acc.append([train_results, test_results])   \n",
    "        cont.append([truth, svm_prediction])\n",
    "        model += 1\n",
    "    results = results.append({'name': name, 'accuracy' : acc}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n",
      "vm  0.5639344262295082\n",
      "vn  0.6131147540983607\n",
      "293\n",
      "vm  0.5639344262295082\n",
      "vn  0.6131147540983607\n",
      "293\n",
      "vm  0.5639344262295082\n",
      "vn  0.6131147540983607\n",
      "293\n",
      "vm  0.5639344262295082\n",
      "vn  0.6131147540983607\n",
      "293\n",
      "vm  0.5639344262295082\n",
      "vn  0.6131147540983607\n",
      "nlp\n",
      "precision:  0.4812286689419795\n",
      "recall:  0.3634020618556701\n",
      "F1:  0.41409691629955947\n",
      "nlp0\n",
      "precision:  0.6028938906752411\n",
      "recall:  0.7115749525616698\n",
      "F1:  0.41409691629955947\n",
      "ave\n",
      "precision:  0.5420612798086103\n",
      "recall:  0.5374885072086699\n",
      "F1:  0.41409691629955947\n"
     ]
    }
   ],
   "source": [
    "#svm = SVC(C=10, kernel='rbf', gamma=2) #vm 52.3% vn 61.0%\n",
    "#svm = SVC(C=2, kernel='rbf', gamma=128) #vm 56.4% vn 61.3%\n",
    "svm = SVC(C=10, kernel='rbf', gamma=2) \n",
    "train_num = 5\n",
    "for i in range(train_num):\n",
    "    svm.fit(X, Y)\n",
    "    Y2_hat = svm.predict(X2)\n",
    "    vn = np.sum(Y2_hat == Yn2)/len(Yn2)\n",
    "    vm = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "    print(np.sum(Y2_hat))\n",
    "    print(\"vm \", vm)\n",
    "    print(\"vn \",vn)\n",
    "    \n",
    "precision = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2)-np.sum(Y2))\n",
    "f10 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp0\")\n",
    "print(\"precision: \", precision0)\n",
    "print(\"recall: \", recall0)\n",
    "print(\"F1: \", f10)\n",
    "\n",
    "print(\"ave\")\n",
    "print(\"precision: \", (precision+precision0)/2)\n",
    "print(\"recall: \", (recall+recall0)/2)\n",
    "print(\"F1: \", (f1+f10)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Best Model: 11\n",
      "\n",
      "SVM\n",
      "         no  social  Total\n",
      "no      412     191    603\n",
      "social   96     261    357\n",
      "Total   508     452    960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "model = input(\"Enter Best Model: \")\n",
    "best = cont[int(model)]\n",
    "rf_ct = pd.crosstab(best[1], best[0], margins=True)\n",
    "rf_ct.columns = [\"no\", \"social\", \"Total\"]\n",
    "rf_ct.index = [\"no\", \"social\", \"Total\"]\n",
    "print()\n",
    "print(\"SVM\")\n",
    "print(rf_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Sensitivity: 0.57743 Specificity: 0.81102 PPV: 0.73109 NPV: 0.68325 Accuracy: 0.70104\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "Sens = rf_ct.iloc[1][1]/rf_ct.iloc[2][1]\n",
    "Spec = rf_ct.iloc[0][0]/rf_ct.iloc[2][0]\n",
    "PPV = rf_ct.iloc[1][1]/rf_ct.iloc[1][2]\n",
    "NPV = rf_ct.iloc[0][0]/rf_ct.iloc[0][2]\n",
    "ACC = (rf_ct.iloc[0][0] + rf_ct.iloc[1][1]) / rf_ct.iloc[2][2]\n",
    "print(\"Random Forest: Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[412  96]\n",
      " [191 261]]\n",
      "0.6452410383189122\n",
      "0.577433628318584\n",
      "0.7310924369747899\n",
      "0.7010416666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.81      0.74       508\n",
      "          1       0.73      0.58      0.65       452\n",
      "\n",
      "avg / total       0.71      0.70      0.70       960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,classification_report\n",
    "y_true =cont[int(model)][0]\n",
    "y_pred = cont[int(model)][1]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred) )\n",
    "\n",
    "print(recall_score(y_true, y_pred),   )\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  0 : Random Forest trees = 5\n",
      "   Fold 1 accuracy: 59.38 %\n",
      "   Fold 2 accuracy: 58.33 %\n",
      "   Fold 3 accuracy: 66.67 %\n",
      "   Fold 4 accuracy: 62.50 %\n",
      "   Fold 5 accuracy: 58.33 %\n",
      "   Fold 6 accuracy: 60.42 %\n",
      "   Fold 7 accuracy: 64.58 %\n",
      "   Fold 8 accuracy: 67.71 %\n",
      "   Fold 9 accuracy: 65.62 %\n",
      "   Fold 10 accuracy: 56.25 %\n",
      "     Overall test accuracy: 61.98 %\n",
      "     Overall training accuracy: 96.25 %\n",
      "model  1 : Random Forest trees = 10\n",
      "   Fold 1 accuracy: 69.79 %\n",
      "   Fold 2 accuracy: 63.54 %\n",
      "   Fold 3 accuracy: 70.83 %\n",
      "   Fold 4 accuracy: 61.46 %\n",
      "   Fold 5 accuracy: 63.54 %\n",
      "   Fold 6 accuracy: 64.58 %\n",
      "   Fold 7 accuracy: 67.71 %\n",
      "   Fold 8 accuracy: 63.54 %\n",
      "   Fold 9 accuracy: 67.71 %\n",
      "   Fold 10 accuracy: 67.71 %\n",
      "     Overall test accuracy: 66.04 %\n",
      "     Overall training accuracy: 98.85 %\n",
      "model  2 : Random Forest trees = 50\n",
      "   Fold 1 accuracy: 66.67 %\n",
      "   Fold 2 accuracy: 68.75 %\n",
      "   Fold 3 accuracy: 67.71 %\n",
      "   Fold 4 accuracy: 67.71 %\n",
      "   Fold 5 accuracy: 78.12 %\n",
      "   Fold 6 accuracy: 62.50 %\n",
      "   Fold 7 accuracy: 66.67 %\n",
      "   Fold 8 accuracy: 71.88 %\n",
      "   Fold 9 accuracy: 62.50 %\n",
      "   Fold 10 accuracy: 69.79 %\n",
      "     Overall test accuracy: 68.23 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  3 : Random Forest trees = 100\n",
      "   Fold 1 accuracy: 69.79 %\n",
      "   Fold 2 accuracy: 69.79 %\n",
      "   Fold 3 accuracy: 70.83 %\n",
      "   Fold 4 accuracy: 69.79 %\n",
      "   Fold 5 accuracy: 65.62 %\n",
      "   Fold 6 accuracy: 67.71 %\n",
      "   Fold 7 accuracy: 58.33 %\n",
      "   Fold 8 accuracy: 65.62 %\n",
      "   Fold 9 accuracy: 73.96 %\n",
      "   Fold 10 accuracy: 67.71 %\n",
      "     Overall test accuracy: 67.92 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  4 : Random Forest trees = 200\n",
      "   Fold 1 accuracy: 69.79 %\n",
      "   Fold 2 accuracy: 64.58 %\n",
      "   Fold 3 accuracy: 70.83 %\n",
      "   Fold 4 accuracy: 68.75 %\n",
      "   Fold 5 accuracy: 72.92 %\n",
      "   Fold 6 accuracy: 69.79 %\n",
      "   Fold 7 accuracy: 65.62 %\n",
      "   Fold 8 accuracy: 73.96 %\n",
      "   Fold 9 accuracy: 72.92 %\n",
      "   Fold 10 accuracy: 60.42 %\n",
      "     Overall test accuracy: 68.96 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  5 : Random Forest trees = 300\n",
      "   Fold 1 accuracy: 68.75 %\n",
      "   Fold 2 accuracy: 75.00 %\n",
      "   Fold 3 accuracy: 54.17 %\n",
      "   Fold 4 accuracy: 70.83 %\n",
      "   Fold 5 accuracy: 66.67 %\n",
      "   Fold 6 accuracy: 71.88 %\n",
      "   Fold 7 accuracy: 63.54 %\n",
      "   Fold 8 accuracy: 73.96 %\n",
      "   Fold 9 accuracy: 73.96 %\n",
      "   Fold 10 accuracy: 66.67 %\n",
      "     Overall test accuracy: 68.54 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  6 : Random Forest trees = 400\n",
      "   Fold 1 accuracy: 64.58 %\n",
      "   Fold 2 accuracy: 77.08 %\n",
      "   Fold 3 accuracy: 69.79 %\n",
      "   Fold 4 accuracy: 64.58 %\n",
      "   Fold 5 accuracy: 68.75 %\n",
      "   Fold 6 accuracy: 66.67 %\n",
      "   Fold 7 accuracy: 73.96 %\n",
      "   Fold 8 accuracy: 65.62 %\n",
      "   Fold 9 accuracy: 70.83 %\n",
      "   Fold 10 accuracy: 69.79 %\n",
      "     Overall test accuracy: 69.17 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  7 : Random Forest trees = 500\n",
      "   Fold 1 accuracy: 72.92 %\n",
      "   Fold 2 accuracy: 60.42 %\n",
      "   Fold 3 accuracy: 72.92 %\n",
      "   Fold 4 accuracy: 69.79 %\n",
      "   Fold 5 accuracy: 68.75 %\n",
      "   Fold 6 accuracy: 77.08 %\n",
      "   Fold 7 accuracy: 65.62 %\n",
      "   Fold 8 accuracy: 59.38 %\n",
      "   Fold 9 accuracy: 71.88 %\n",
      "   Fold 10 accuracy: 63.54 %\n",
      "     Overall test accuracy: 68.23 %\n",
      "     Overall training accuracy: 100.00 %\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# RandomForest\n",
    "model=0\n",
    "results = []\n",
    "cont = []\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "trees = [5, 10, 50, 100, 200, 300, 400, 500]\n",
    "for t in range(len(trees)):\n",
    "    fold = 1\n",
    "    truth = []\n",
    "    rf_prediction = []\n",
    "    print(\"model \", t, \": Random Forest trees = \" + str(trees[t]))\n",
    "    test_count = 0\n",
    "    rf = RandomForestClassifier(n_estimators=trees[t], criterion='entropy', n_jobs=-1, )\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        trainX = X[train_idx]\n",
    "        trainY = Y[train_idx]\n",
    "        testX = X[test_idx]\n",
    "        testY = Y[test_idx]\n",
    "        truth.append(testY)\n",
    "        rf.fit(trainX, trainY)\n",
    "        Y_hat = rf.predict(testX)\n",
    "        rf_prediction.append(Y_hat)\n",
    "        print(\"   Fold %d accuracy: %.2f %%\" % (fold, ((np.sum(Y_hat == testY)/len(testY)) * 100.0)))                        \n",
    "        fold += 1\n",
    "    truth = np.concatenate(truth, axis=0)    \n",
    "    rf_prediction = np.concatenate(rf_prediction, axis=0)\n",
    "    test_results = np.sum(rf_prediction == truth)/len(truth)\n",
    "    print(\"     Overall test accuracy: %.2f %%\" % (test_results * 100))  \n",
    "    rf = rf.fit(X, Y)\n",
    "    Y_hat = rf.predict(X)\n",
    "    train_results = np.sum(Y_hat == Y)/len(Y)\n",
    "    print(\"     Overall training accuracy: %.2f %%\" % (train_results * 100.0))  \n",
    "    results.append([train_results, test_results])   \n",
    "    cont.append([truth, rf_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n",
      "vm  0.5530054644808743\n",
      "vn  0.6174863387978142\n",
      "367\n",
      "vm  0.5508196721311476\n",
      "vn  0.6218579234972678\n",
      "375\n",
      "vm  0.5486338797814208\n",
      "vn  0.6240437158469946\n",
      "382\n",
      "vm  0.5409836065573771\n",
      "vn  0.614207650273224\n",
      "386\n",
      "vm  0.5453551912568306\n",
      "vn  0.6207650273224044\n",
      "nlp\n",
      "precision:  0.4637305699481865\n",
      "recall:  0.46134020618556704\n",
      "F1:  0.4625322997416021\n",
      "nlp0\n",
      "precision:  0.6049149338374291\n",
      "recall:  0.6072106261859582\n",
      "F1:  0.4625322997416021\n",
      "ave\n",
      "precision:  0.5343227518928078\n",
      "recall:  0.5342754161857626\n",
      "F1:  0.4625322997416021\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400, criterion='entropy', n_jobs=-1, )\n",
    "train_num = 5\n",
    "for i in range(train_num):\n",
    "    rf.fit(X, Y)\n",
    "    Y2_hat = rf.predict(X2)\n",
    "    vn = np.sum(Y2_hat == Yn2)/len(Yn2)\n",
    "    vm = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "    print(np.sum(Y2_hat))\n",
    "    print(\"vm \", vm)\n",
    "    print(\"vn \",vn)\n",
    "    \n",
    "precision = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2)-np.sum(Y2))\n",
    "f10 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp0\")\n",
    "print(\"precision: \", precision0)\n",
    "print(\"recall: \", recall0)\n",
    "print(\"F1: \", f10)\n",
    "\n",
    "print(\"ave\")\n",
    "print(\"precision: \", (precision+precision0)/2)\n",
    "print(\"recall: \", (recall+recall0)/2)\n",
    "print(\"F1: \", (f1+f10)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Best Model: 6\n",
      "\n",
      "Random Forest\n",
      "         no  social  Total\n",
      "no      366     154    520\n",
      "social  142     298    440\n",
      "Total   508     452    960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "model = input(\"Enter Best Model: \")\n",
    "best = cont[int(model)]\n",
    "rf_ct = pd.crosstab(best[1], best[0], margins=True)\n",
    "rf_ct.columns = [\"no\", \"social\", \"Total\"]\n",
    "rf_ct.index = [\"no\", \"social\", \"Total\"]\n",
    "print()\n",
    "print(\"Random Forest\")\n",
    "print(rf_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Sensitivity: 0.65929 Specificity: 0.72047 PPV: 0.67727 NPV: 0.70385 Accuracy: 0.69167\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "Sens = rf_ct.iloc[1][1]/rf_ct.iloc[2][1]\n",
    "Spec = rf_ct.iloc[0][0]/rf_ct.iloc[2][0]\n",
    "PPV = rf_ct.iloc[1][1]/rf_ct.iloc[1][2]\n",
    "NPV = rf_ct.iloc[0][0]/rf_ct.iloc[0][2]\n",
    "ACC = (rf_ct.iloc[0][0] + rf_ct.iloc[1][1]) / rf_ct.iloc[2][2]\n",
    "print(\"Random Forest: Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[366 142]\n",
      " [154 298]]\n",
      "0.6681614349775785\n",
      "0.6592920353982301\n",
      "0.6772727272727272\n",
      "0.6916666666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.72      0.71       508\n",
      "          1       0.68      0.66      0.67       452\n",
      "\n",
      "avg / total       0.69      0.69      0.69       960\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,classification_report\n",
    "y_true =cont[int(model)][0]\n",
    "y_pred = cont[int(model)][1]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred) )\n",
    "\n",
    "\n",
    "\n",
    "print(recall_score(y_true, y_pred),   )\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.957031\n",
      "Test set score: 0.692708\n",
      "precision:  0.67\n",
      "recall:  0.7204301075268817\n",
      "F1:  0.6943005181347149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.utils import shuffle\n",
    "X, Y = shuffle(X, Y)\n",
    "split = int(len(Y) * 4/5)\n",
    "trainX = X[:split, :]\n",
    "trainY = Y[:split]\n",
    "testX = X[split:, :]\n",
    "testY = Y[split:]\n",
    "\n",
    "#%%\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, alpha=1e-4,\n",
    "                    solver='adam', verbose=False, tol=1e-4, random_state=1)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4,\n",
    "#                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "#                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(trainX, trainY)\n",
    "print(\"Training set score: %f\" % mlp.score(trainX, trainY))\n",
    "print(\"Test set score: %f\" % mlp.score(testX, testY))\n",
    "y_hat = mlp.predict(testX)\n",
    "precision = np.sum(y_hat + testY == 2)/np.sum(y_hat)\n",
    "recall = np.sum(y_hat + testY == 2)/np.sum(testY)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.958333\n",
      "Test set score: 0.453125\n",
      "precision:  0.4891304347826087\n",
      "recall:  0.4368932038834951\n",
      "F1:  0.4615384615384615\n",
      "precision:  0.42\n",
      "recall:  0.47191011235955055\n",
      "F1:  0.4444444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.utils import shuffle\n",
    "X, Yn1 = shuffle(X, Yn1)        # use other label\n",
    "split = int(len(Yn1) * 4/5)\n",
    "trainX = X[:split, :]\n",
    "trainY = Yn1[:split]\n",
    "testX = X[split:, :]\n",
    "testY = Yn1[split:]\n",
    "\n",
    "#%%\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, alpha=1e-4,\n",
    "                    solver='adam', verbose=False, tol=1e-4, random_state=1)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4,\n",
    "#                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "#                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(trainX, trainY)\n",
    "print(\"Training set score: %f\" % mlp.score(trainX, trainY))\n",
    "print(\"Test set score: %f\" % mlp.score(testX, testY))\n",
    "y_hat = mlp.predict(testX)\n",
    "precision = np.sum(y_hat + testY == 2)/np.sum(y_hat)\n",
    "recall = np.sum(y_hat + testY == 2)/np.sum(testY)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision = np.sum(y_hat + testY == 0)/(len(y_hat)-np.sum(y_hat))\n",
    "recall = np.sum(y_hat + testY == 0)/(len(testY)-np.sum(testY))\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409\n",
      "acc vm  0.4852459016393443\n",
      "acc vn  0.5366120218579234\n",
      "nlp\n",
      "precision:  0.46454767726161367\n",
      "recall:  0.4810126582278481\n",
      "F1:  0.472636815920398\n",
      "nlp0\n",
      "precision:  0.5948616600790514\n",
      "recall:  0.5788461538461539\n",
      "F1:  0.5867446393762183\n",
      "manu\n",
      "precision:  0.39853300733496333\n",
      "recall:  0.42010309278350516\n",
      "F1:  0.4090338770388958\n",
      "manu0\n",
      "precision:  0.5553359683794467\n",
      "recall:  0.5332068311195446\n",
      "F1:  0.5440464666021297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, Y = shuffle(X, Y)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,),max_iter=500, alpha=1e-4)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(100,),max_iter=1000, alpha=1e-4) 67.5%\n",
    "mlp.fit(X,Y)\n",
    "\n",
    "Y2_hat = mlp.predict(X2)\n",
    "vn = np.sum(Y2_hat == Yn2)/len(Yn2)\n",
    "vm = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "print(np.sum(Y2_hat))\n",
    "print(\"acc vm \", vm)\n",
    "print(\"acc vn \",vn)\n",
    "\n",
    "precision = np.sum(Y2_hat + Yn2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Yn2 == 2)/np.sum(Yn2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision = np.sum(Y2_hat + Yn2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall = np.sum(Y2_hat + Yn2 == 0)/(len(Yn2)-np.sum(Yn2))\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp0\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"manu\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision = np.sum(Y2_hat + Y2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall = np.sum(Y2_hat + Y2 == 0)/(len(Y2)-np.sum(Y2))\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"manu0\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434\n",
      "acc vm  0.43387978142076505\n",
      "acc vn  0.7387978142076502\n",
      "nlp\n",
      "precision:  0.6797235023041475\n",
      "recall:  0.7468354430379747\n",
      "F1:  0.7117008443908323\n",
      "nlp0\n",
      "precision:  0.7920997920997921\n",
      "recall:  0.7326923076923076\n",
      "F1:  0.7612387612387612\n",
      "manu\n",
      "precision:  0.35023041474654376\n",
      "recall:  0.3917525773195876\n",
      "F1:  0.3698296836982968\n",
      "manu0\n",
      "precision:  0.5093555093555093\n",
      "recall:  0.4648956356736243\n",
      "F1:  0.48611111111111116\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, Yn1 = shuffle(X, Yn1)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(300,),max_iter=500, alpha=1e-4)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(100,),max_iter=1000, alpha=1e-4) 67.5%\n",
    "mlp.fit(X,Yn1)\n",
    "\n",
    "Y2_hat = mlp.predict(X2)\n",
    "vn = np.sum(Y2_hat == Yn2)/len(Yn2)\n",
    "\n",
    "vm = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "print(np.sum(Y2_hat))\n",
    "print(\"acc vm \", vm)\n",
    "print(\"acc vn \",vn)\n",
    "\n",
    "precision = np.sum(Y2_hat + Yn2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Yn2 == 2)/np.sum(Yn2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision = np.sum(Y2_hat + Yn2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall = np.sum(Y2_hat + Yn2 == 0)/(len(Yn2)-np.sum(Yn2))\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp0\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"manu\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision = np.sum(Y2_hat + Y2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall = np.sum(Y2_hat + Y2 == 0)/(len(Y2)-np.sum(Y2))\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"manu0\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7359116472019698, 0.7397638753651412, 0.7364698028147967)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.6797235023041475+0.7920997920997921)/2, (0.7468354430379747+0.7326923076923076)/2, (0.7117008443908323+0.7612387612387612)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
