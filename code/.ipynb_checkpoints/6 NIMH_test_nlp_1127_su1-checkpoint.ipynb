{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIMH Project - Machine Learning - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import math\n",
    "import chardet\n",
    "os.chdir('Z:/project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pat_visit</th>\n",
       "      <th>m1</th>\n",
       "      <th>n1</th>\n",
       "      <th>txt1</th>\n",
       "      <th>fsize</th>\n",
       "      <th>m1_1</th>\n",
       "      <th>n1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19808302_2359420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MRN:                     19808302\\r\\n...... ME...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19808302_2356111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MRN:                     19808302\\r\\n...... Me...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2574689_2276293</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MRN:                     2574689\\r\\n...... Med...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5762778_190693829</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MRN:  05762778           ...... MRN:  05762778...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>18316273_2121713</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MRN:           18316273\\r\\n\\r\\n...... MRN:    ...</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          pat_visit  m1  n1  \\\n",
       "0           0   19808302_2359420   0   0   \n",
       "1           1   19808302_2356111   0   0   \n",
       "2           2    2574689_2276293   0   0   \n",
       "3           3  5762778_190693829   0   0   \n",
       "4           4   18316273_2121713   0   0   \n",
       "\n",
       "                                                txt1  fsize  m1_1  n1_1  \n",
       "0  MRN:                     19808302\\r\\n...... ME...     18     0     0  \n",
       "1  MRN:                     19808302\\r\\n...... Me...     18     0     0  \n",
       "2  MRN:                     2574689\\r\\n...... Med...     14     0     0  \n",
       "3  MRN:  05762778           ...... MRN:  05762778...     11     0     0  \n",
       "4  MRN:           18316273\\r\\n\\r\\n...... MRN:    ...     45     0     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "#data = pd.read_csv(\"./results/pat_visit_score_match_1127.csv\")\n",
    "data = pd.read_csv(\"./results/train_2925_2.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2925, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pat_visit</th>\n",
       "      <th>m1</th>\n",
       "      <th>n1</th>\n",
       "      <th>txt1</th>\n",
       "      <th>fsize</th>\n",
       "      <th>m1_1</th>\n",
       "      <th>n1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>766</td>\n",
       "      <td>14221485_2180859</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MRN:                     14221485\\r\\n...... Me...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>1536</td>\n",
       "      <td>12585717_190743768</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>MRN: 12585717\\r\\n...... MRN: 12585717\\r\\n........</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1459</td>\n",
       "      <td>17063058_2422970</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>MRN:                     17063058\\r\\n...... Me...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>6311286_1941616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MRN:                     6311286\\r\\n...... MRN...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>1347</td>\n",
       "      <td>20463231_189138737</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MRN: 20463231\\r\\n...... MRN: 20463231\\r\\n........</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0           pat_visit  m1  n1  \\\n",
       "766          766    14221485_2180859   0   1   \n",
       "1536        1536  12585717_190743768   0   2   \n",
       "1459        1459    17063058_2422970   0   2   \n",
       "23            23     6311286_1941616   0   0   \n",
       "1347        1347  20463231_189138737   0   1   \n",
       "\n",
       "                                                   txt1  fsize  m1_1  n1_1  \n",
       "766   MRN:                     14221485\\r\\n...... Me...     13     0     0  \n",
       "1536  MRN: 12585717\\r\\n...... MRN: 12585717\\r\\n........     38     0     1  \n",
       "1459  MRN:                     17063058\\r\\n...... Me...     23     0     1  \n",
       "23    MRN:                     6311286\\r\\n...... MRN...     23     0     0  \n",
       "1347  MRN: 20463231\\r\\n...... MRN: 20463231\\r\\n........     43     0     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.utils import shuffle\n",
    "#data = shuffle(data)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelm=data[data.columns[6]].tolist()\n",
    "labeln=data[data.columns[7]].tolist()\n",
    "#labelm2=data[data.columns[11]].tolist()\n",
    "#labeln2=data[data.columns[12]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6136752136752137"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_m1 = np.array(labelm)\n",
    "arr_n1 = np.array(labeln)\n",
    "#arr_m2 = np.array(labelm2)\n",
    "#arr_n2 = np.array(labeln2)\n",
    "sum(arr_m1 == arr_n1)/len(arr_m1)  #, sum(arr_m2 == arr_n2)/len(arr_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "corpusList=data[data.columns[4]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpusList2=data[data.columns[7]].tolist()\n",
    "#corpusList[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2925"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpusList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(corpusList2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def tokenize(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = [ token for token in tokens if re.search('(^[a-zA-Z]+$)', token) ]\n",
    "    a=[]\n",
    "    for i in filtered_tokens:\n",
    "        a.append(WordNetLemmatizer().lemmatize(i,'v'))\n",
    "    return a\n",
    "    #return filtered_tokens\n",
    "\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(2925, 2499106)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "cv = TfidfVectorizer(lowercase=True,\n",
    "                     ngram_range=(1, 4), preprocessor=None, stop_words='english',\n",
    "                     strip_accents=None, tokenizer=tokenize, vocabulary=None)\n",
    "X1 = cv.fit_transform(corpusList)\n",
    "lexicon = cv.get_feature_names()\n",
    "#print (lexicon)\n",
    "print()\n",
    "\n",
    "#%%\n",
    "x=X1  ## for select fetures \n",
    "print(x.shape)\n",
    "\n",
    "pkl.dump( x, open( \"./results/tfidf_2925_2.pickle\", \"wb\" ) )\n",
    "pkl.dump( lexicon, open( \"./results/lexicon_2925_2.pickle\", \"wb\" ) )\n",
    "#x1 = pkl.load( open( \"./results/tfidf_4801395.pickle\", \"rb\" ) )\n",
    "#lexicon1 = pkl.load( open( \"./results/lexicon_4801395.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2925, 2499106)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\"\"\"cv2 = TfidfVectorizer(lowercase=True,\n",
    "                     ngram_range=(1, 4), preprocessor=None, stop_words='english',\n",
    "                     strip_accents=None, tokenizer=tokenize, vocabulary=None)\n",
    "X2 = cv2.fit_transform(corpusList2)\n",
    "lexicon2 = cv2.get_feature_names()\n",
    "#print (lexicon)\n",
    "print()\n",
    "\n",
    "#%%\n",
    "x2=X2  ## for select fetures \n",
    "print(x2.shape)\n",
    "\n",
    "pkl.dump( x2, open( \"./results/tfidf_1885_2.pickle\", \"wb\" ) )\n",
    "pkl.dump( lexicon2, open( \"./results/lexicon_1885_2.pickle\", \"wb\" ) )\n",
    "#x1 = pkl.load( open( \"./results/tfidf_4801395.pickle\", \"rb\" ) )\n",
    "#lexicon1 = pkl.load( open( \"./results/lexicon_4801395.pickle\", \"rb\" ) )\"\"\"\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ym = np.array(labelm)\n",
    "Yn = np.array(labeln)\n",
    "#Ym2 = np.array(labelm2)\n",
    "#Yn2 = np.array(labeln2)\n",
    "pkl.dump( Ym, open( \"./results/ym_2925_2.pickle\", \"wb\" ) )\n",
    "pkl.dump( Yn, open( \"./results/yn_2925_2.pickle\", \"wb\" ) )\n",
    "#pkl.dump( Ym2, open( \"./results/ym_1885_2.pickle\", \"wb\" ) )\n",
    "#pkl.dump( Yn2, open( \"./results/yn_1885_2.pickle\", \"wb\" ) )\n",
    "#print(Y)  ## class level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#%%\n",
    "#test\n",
    "cvt = TfidfVectorizer(lowercase=True,\n",
    "                     ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
    "                     strip_accents=None, tokenizer=tokenize, vocabulary=None)\n",
    "\n",
    "X1t = cvt.fit_transform(corpusList_test)\n",
    "print(X1t.shape)\n",
    "print()\n",
    "lexicon_test = cvt.get_feature_names()\n",
    "#print (lexicon)\n",
    "print()\n",
    "\n",
    "#%%\n",
    "xt=X1t  ## for select fetures \n",
    "print(xt.shape)\n",
    "\n",
    "Ym = np.array(labels_testm)\n",
    "Yn = np.array(labels_testn)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0] [0 0 1 1 1 1 1 1 1 1] [1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0] [0 1 1 1 1 1 1 1 1 1] [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(Ym[0:10], Ym[2233:2243], Ym[2920:])  ## class level\n",
    "print(Yn[0:10], Yn[1181:1191], Yn[2920:])  ## class level\n",
    "#print(Ym2[0:10], Ym2[480:490], Ym2[1865:])  ## class level\n",
    "#print(Yn2[0:10], Yn2[480:490], Yn2[1865:])  ## class level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2925, 800)\n"
     ]
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=800).fit_transform(x, Yn)   # select 800 features\n",
    "\n",
    "#%%\n",
    "X=X_new        # make unque name for next cell \n",
    "print(X.shape)\n",
    "#Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump( X, open( \"./results/tfidf_2925_800_2.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pkl.load( open( \"./results/tfidf_2925.pickle\", \"rb\" ) )\n",
    "Yn = pkl.load( open( \"./results/yn_2925.pickle\", \"rb\" ) )\n",
    "\n",
    "X_new2 = SelectKBest(chi2, k=1200).fit_transform(x, Yn)\n",
    "pkl.dump( X_new2, open( \"./results/tfidf_2925_1200_2.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pkl.load( open( \"./results/tfidf_2925_800_2.pickle\", \"rb\" ) )\n",
    "Ym = pkl.load( open( \"./results/ym_2925_2.pickle\", \"rb\" ) )\n",
    "Yn = pkl.load( open( \"./results/yn_2925_2.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_new,Ym,Yn  = shuffle(X_new,Ym,Yn)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_new[:1900]\n",
    "X2 = X_new[1900:]\n",
    "Y = Yn[:1900]\n",
    "Y2 = Yn[1900:]\n",
    "Ym1 = Ym[:1900]\n",
    "Ym2 = Ym[1900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1395, 600)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"X2_new = SelectKBest(chi2, k=600).fit_transform(xt, Ym)   # select 600 features\n",
    "X2_new.shape\n",
    "\n",
    "#%%\n",
    "X2=X2_new        # make unque name for next cell \n",
    "X2_new.shape\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  0 : ExtraTreesClassifier = 10\n",
      "   Fold 1 accuracy: 81.58 %\n",
      "   Fold 2 accuracy: 82.11 %\n",
      "   Fold 3 accuracy: 81.05 %\n",
      "   Fold 4 accuracy: 77.37 %\n",
      "   Fold 5 accuracy: 76.32 %\n",
      "   Fold 6 accuracy: 80.53 %\n",
      "   Fold 7 accuracy: 78.95 %\n",
      "   Fold 8 accuracy: 79.47 %\n",
      "   Fold 9 accuracy: 80.53 %\n",
      "   Fold 10 accuracy: 80.00 %\n",
      "     Overall test accuracy: 79.79 %\n",
      "     Overall training accuracy: 98.95 %\n",
      "model  1 : ExtraTreesClassifier = 30\n",
      "   Fold 1 accuracy: 78.42 %\n",
      "   Fold 2 accuracy: 81.05 %\n",
      "   Fold 3 accuracy: 83.68 %\n",
      "   Fold 4 accuracy: 79.47 %\n",
      "   Fold 5 accuracy: 81.58 %\n",
      "   Fold 6 accuracy: 83.16 %\n",
      "   Fold 7 accuracy: 81.05 %\n",
      "   Fold 8 accuracy: 81.58 %\n",
      "   Fold 9 accuracy: 76.32 %\n",
      "   Fold 10 accuracy: 77.37 %\n",
      "     Overall test accuracy: 80.37 %\n",
      "     Overall training accuracy: 99.00 %\n",
      "model  2 : ExtraTreesClassifier = 60\n",
      "   Fold 1 accuracy: 78.95 %\n",
      "   Fold 2 accuracy: 83.16 %\n",
      "   Fold 3 accuracy: 80.53 %\n",
      "   Fold 4 accuracy: 84.21 %\n",
      "   Fold 5 accuracy: 80.00 %\n",
      "   Fold 6 accuracy: 76.84 %\n",
      "   Fold 7 accuracy: 81.58 %\n",
      "   Fold 8 accuracy: 83.68 %\n",
      "   Fold 9 accuracy: 83.16 %\n",
      "   Fold 10 accuracy: 84.21 %\n",
      "     Overall test accuracy: 81.63 %\n",
      "     Overall training accuracy: 99.05 %\n",
      "model  3 : ExtraTreesClassifier = 100\n",
      "   Fold 1 accuracy: 76.32 %\n",
      "   Fold 2 accuracy: 83.68 %\n",
      "   Fold 3 accuracy: 83.68 %\n",
      "   Fold 4 accuracy: 79.47 %\n",
      "   Fold 5 accuracy: 82.11 %\n",
      "   Fold 6 accuracy: 80.53 %\n",
      "   Fold 7 accuracy: 82.11 %\n",
      "   Fold 8 accuracy: 83.68 %\n",
      "   Fold 9 accuracy: 83.16 %\n",
      "   Fold 10 accuracy: 80.00 %\n",
      "     Overall test accuracy: 81.47 %\n",
      "     Overall training accuracy: 99.32 %\n",
      "model  4 : ExtraTreesClassifier = 300\n",
      "   Fold 1 accuracy: 80.53 %\n",
      "   Fold 2 accuracy: 83.16 %\n",
      "   Fold 3 accuracy: 77.37 %\n",
      "   Fold 4 accuracy: 78.95 %\n",
      "   Fold 5 accuracy: 80.53 %\n",
      "   Fold 6 accuracy: 83.16 %\n",
      "   Fold 7 accuracy: 81.58 %\n",
      "   Fold 8 accuracy: 77.89 %\n",
      "   Fold 9 accuracy: 83.16 %\n",
      "   Fold 10 accuracy: 84.21 %\n",
      "     Overall test accuracy: 81.05 %\n",
      "     Overall training accuracy: 99.37 %\n",
      "model  5 : ExtraTreesClassifier = 500\n",
      "   Fold 1 accuracy: 81.05 %\n",
      "   Fold 2 accuracy: 83.68 %\n",
      "   Fold 3 accuracy: 82.63 %\n",
      "   Fold 4 accuracy: 79.47 %\n",
      "   Fold 5 accuracy: 82.11 %\n",
      "   Fold 6 accuracy: 81.05 %\n",
      "   Fold 7 accuracy: 82.63 %\n",
      "   Fold 8 accuracy: 80.53 %\n",
      "   Fold 9 accuracy: 81.05 %\n",
      "   Fold 10 accuracy: 78.42 %\n",
      "     Overall test accuracy: 81.26 %\n",
      "     Overall training accuracy: 99.26 %\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# ExtraTreesClassifier\n",
    "model=0\n",
    "results = []\n",
    "cont = []\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "trees = [10, 30, 60, 100, 300, 500]\n",
    "for t in range(len(trees)):\n",
    "    fold = 1\n",
    "    truth = []\n",
    "    rf_prediction = []\n",
    "    print(\"model \", t, \": ExtraTreesClassifier = \" + str(trees[t]))\n",
    "    test_count = 0\n",
    "    rf = ExtraTreesClassifier(bootstrap=False,\n",
    "           criterion='entropy', max_depth=15, max_features=0.9,\n",
    "           max_leaf_nodes=None, min_impurity_decrease=1e-045,\n",
    "           min_samples_leaf=1, min_samples_split=3,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=trees[t], n_jobs=-1,\n",
    "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        trainX = X[train_idx]\n",
    "        trainY = Y[train_idx]\n",
    "        testX = X[test_idx]\n",
    "        testY = Y[test_idx]\n",
    "        truth.append(testY)\n",
    "        rf.fit(trainX, trainY)\n",
    "        Y_hat = rf.predict(testX)\n",
    "        rf_prediction.append(Y_hat)\n",
    "        print(\"   Fold %d accuracy: %.2f %%\" % (fold, ((np.sum(Y_hat == testY)/len(testY)) * 100.0)))                        \n",
    "        fold += 1\n",
    "    truth = np.concatenate(truth, axis=0)    \n",
    "    rf_prediction = np.concatenate(rf_prediction, axis=0)\n",
    "    test_results = np.sum(rf_prediction == truth)/len(truth)\n",
    "    print(\"     Overall test accuracy: %.2f %%\" % (test_results * 100))  \n",
    "    rf = rf.fit(X, Y)\n",
    "    Y_hat = rf.predict(X)\n",
    "    train_results = np.sum(Y_hat == Y)/len(Y)\n",
    "    print(\"     Overall training accuracy: %.2f %%\" % (train_results * 100.0))  \n",
    "    results.append([train_results, test_results])   \n",
    "    cont.append([truth, rf_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ExtraTreesClassifier(bootstrap=False,\n",
    "       criterion='entropy', max_depth=15, max_features=0.9,\n",
    "       max_leaf_nodes=None, min_impurity_decrease=1e-045,\n",
    "       min_samples_leaf=1, min_samples_split=3,\n",
    "       min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=-1,      #trees[t] = 100\n",
    "       oob_score=False, random_state=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490\n",
      "vm  0.6224390243902439\n",
      "vn  0.7873170731707317\n",
      "nlp\n",
      "precision:  0.7224489795918367\n",
      "recall:  0.8119266055045872\n",
      "F1:  0.7645788336933045\n",
      "nlp0\n",
      "precision:  0.8467289719626169\n",
      "recall:  0.769100169779287\n",
      "F1:  0.7645788336933045\n",
      "ave\n",
      "precision:  0.7845889757772269\n",
      "recall:  0.790513387641937\n",
      "F1:  0.7645788336933045\n"
     ]
    }
   ],
   "source": [
    "train_num = 1\n",
    "for i in range(train_num):\n",
    "    rf.fit(X, Y)\n",
    "    Y2_hat = rf.predict(X2)\n",
    "    vm = np.sum(Y2_hat == Ym2)/len(Ym2)\n",
    "    vn = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "    print(np.sum(Y2_hat))\n",
    "    print(\"vm \", vm)\n",
    "    print(\"vn \",vn)\n",
    "    \n",
    "precision = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2)-np.sum(Y2))\n",
    "f10 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp0\")\n",
    "print(\"precision: \", precision0)\n",
    "print(\"recall: \", recall0)\n",
    "print(\"F1: \", f10)\n",
    "\n",
    "print(\"ave\")\n",
    "print(\"precision: \", (precision+precision0)/2)\n",
    "print(\"recall: \", (recall+recall0)/2)\n",
    "print(\"F1: \", (f1+f10)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(885, 800)\n",
      "885\n"
     ]
    }
   ],
   "source": [
    "print(X2.shape)\n",
    "print(len(Y2_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Best Model: 2\n",
      "\n",
      "ExtraTrees\n",
      "          no  social  Total\n",
      "no       896     149   1045\n",
      "social   200     655    855\n",
      "Total   1096     804   1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "model = input(\"Enter Best Model: \")\n",
    "best = cont[int(model)]\n",
    "rf_ct = pd.crosstab(best[1], best[0], margins=True)\n",
    "rf_ct.columns = [\"no\", \"social\", \"Total\"]\n",
    "rf_ct.index = [\"no\", \"social\", \"Total\"]\n",
    "print()\n",
    "print(\"ExtraTrees\")\n",
    "print(rf_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[896 200]\n",
      " [149 655]]\n",
      "0.7896323086196504\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,classification_report\n",
    "y_true =cont[int(model)][0]\n",
    "y_pred = cont[int(model)][1]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8146766169154229\n",
      "0.7660818713450293\n",
      "0.8163157894736842\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.82      0.84      1096\n",
      "          1       0.77      0.81      0.79       804\n",
      "\n",
      "avg / total       0.82      0.82      0.82      1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_true, y_pred),   )\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees: Sensitivity: 0.81468 Specificity: 0.81752 PPV: 0.76608 NPV: 0.85742 Accuracy: 0.81632\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "Sens = rf_ct.iloc[1][1]/rf_ct.iloc[2][1]\n",
    "Spec = rf_ct.iloc[0][0]/rf_ct.iloc[2][0]\n",
    "PPV = rf_ct.iloc[1][1]/rf_ct.iloc[1][2]\n",
    "NPV = rf_ct.iloc[0][0]/rf_ct.iloc[0][2]\n",
    "ACC = (rf_ct.iloc[0][0] + rf_ct.iloc[1][1]) / rf_ct.iloc[2][2]\n",
    "print(\"ExtraTrees: Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  0.8160974325453028\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(best[0], best[1], pos_label=1)\n",
    "roc_auc = auc(rf_fpr, rf_tpr)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(rf_fpr, rf_tpr, label='ExtraTrees')\n",
    "plt.xlabel('False positive rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(\"AUC = \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0: SVM RBF Gamma=1.000 C=1.00\n",
      "   Fold 1 accuracy: 67.89 %\n",
      "   Fold 2 accuracy: 75.79 %\n",
      "   Fold 3 accuracy: 68.42 %\n",
      "   Fold 4 accuracy: 64.21 %\n",
      "   Fold 5 accuracy: 72.11 %\n",
      "   Fold 6 accuracy: 65.79 %\n",
      "   Fold 7 accuracy: 68.95 %\n",
      "   Fold 8 accuracy: 72.63 %\n",
      "   Fold 9 accuracy: 67.89 %\n",
      "   Fold 10 accuracy: 73.68 %\n",
      "     Overall test accuracy: 69.74 %\n",
      "     Overall training accuracy: 71.32 %\n",
      "model 1: SVM RBF Gamma=1.000 C=2.00\n",
      "   Fold 1 accuracy: 76.32 %\n",
      "   Fold 2 accuracy: 69.47 %\n",
      "   Fold 3 accuracy: 75.26 %\n",
      "   Fold 4 accuracy: 71.58 %\n",
      "   Fold 5 accuracy: 73.16 %\n",
      "   Fold 6 accuracy: 74.21 %\n",
      "   Fold 7 accuracy: 73.16 %\n",
      "   Fold 8 accuracy: 75.26 %\n",
      "   Fold 9 accuracy: 69.47 %\n",
      "   Fold 10 accuracy: 73.68 %\n",
      "     Overall test accuracy: 73.16 %\n",
      "     Overall training accuracy: 75.58 %\n",
      "model 2: SVM RBF Gamma=1.000 C=4.00\n",
      "   Fold 1 accuracy: 76.84 %\n",
      "   Fold 2 accuracy: 72.11 %\n",
      "   Fold 3 accuracy: 80.00 %\n",
      "   Fold 4 accuracy: 77.89 %\n",
      "   Fold 5 accuracy: 72.63 %\n",
      "   Fold 6 accuracy: 76.32 %\n",
      "   Fold 7 accuracy: 74.21 %\n",
      "   Fold 8 accuracy: 76.84 %\n",
      "   Fold 9 accuracy: 76.32 %\n",
      "   Fold 10 accuracy: 76.32 %\n",
      "     Overall test accuracy: 75.95 %\n",
      "     Overall training accuracy: 79.00 %\n",
      "model 3: SVM RBF Gamma=1.000 C=6.00\n",
      "   Fold 1 accuracy: 79.47 %\n",
      "   Fold 2 accuracy: 73.16 %\n",
      "   Fold 3 accuracy: 80.00 %\n",
      "   Fold 4 accuracy: 73.16 %\n",
      "   Fold 5 accuracy: 73.16 %\n",
      "   Fold 6 accuracy: 74.74 %\n",
      "   Fold 7 accuracy: 76.32 %\n",
      "   Fold 8 accuracy: 83.68 %\n",
      "   Fold 9 accuracy: 78.42 %\n",
      "   Fold 10 accuracy: 77.37 %\n",
      "     Overall test accuracy: 76.95 %\n",
      "     Overall training accuracy: 80.58 %\n",
      "model 4: SVM RBF Gamma=1.000 C=8.00\n",
      "   Fold 1 accuracy: 75.26 %\n",
      "   Fold 2 accuracy: 77.89 %\n",
      "   Fold 3 accuracy: 72.11 %\n",
      "   Fold 4 accuracy: 84.74 %\n",
      "   Fold 5 accuracy: 79.47 %\n",
      "   Fold 6 accuracy: 78.42 %\n",
      "   Fold 7 accuracy: 76.32 %\n",
      "   Fold 8 accuracy: 77.89 %\n",
      "   Fold 9 accuracy: 77.89 %\n",
      "   Fold 10 accuracy: 77.89 %\n",
      "     Overall test accuracy: 77.79 %\n",
      "     Overall training accuracy: 81.32 %\n",
      "model 5: SVM RBF Gamma=1.000 C=10.00\n",
      "   Fold 1 accuracy: 81.05 %\n",
      "   Fold 2 accuracy: 77.89 %\n",
      "   Fold 3 accuracy: 80.53 %\n",
      "   Fold 4 accuracy: 74.74 %\n",
      "   Fold 5 accuracy: 82.11 %\n",
      "   Fold 6 accuracy: 80.53 %\n",
      "   Fold 7 accuracy: 77.89 %\n",
      "   Fold 8 accuracy: 75.26 %\n",
      "   Fold 9 accuracy: 77.89 %\n",
      "   Fold 10 accuracy: 75.26 %\n",
      "     Overall test accuracy: 78.32 %\n",
      "     Overall training accuracy: 81.95 %\n",
      "model 6: SVM RBF Gamma=2.000 C=1.00\n",
      "   Fold 1 accuracy: 67.37 %\n",
      "   Fold 2 accuracy: 76.32 %\n",
      "   Fold 3 accuracy: 79.47 %\n",
      "   Fold 4 accuracy: 72.63 %\n",
      "   Fold 5 accuracy: 66.84 %\n",
      "   Fold 6 accuracy: 74.21 %\n",
      "   Fold 7 accuracy: 77.37 %\n",
      "   Fold 8 accuracy: 76.84 %\n",
      "   Fold 9 accuracy: 70.53 %\n",
      "   Fold 10 accuracy: 74.74 %\n",
      "     Overall test accuracy: 73.63 %\n",
      "     Overall training accuracy: 75.84 %\n",
      "model 7: SVM RBF Gamma=2.000 C=2.00\n",
      "   Fold 1 accuracy: 70.53 %\n",
      "   Fold 2 accuracy: 75.79 %\n",
      "   Fold 3 accuracy: 76.32 %\n",
      "   Fold 4 accuracy: 83.68 %\n",
      "   Fold 5 accuracy: 76.32 %\n",
      "   Fold 6 accuracy: 73.16 %\n",
      "   Fold 7 accuracy: 76.32 %\n",
      "   Fold 8 accuracy: 76.32 %\n",
      "   Fold 9 accuracy: 76.32 %\n",
      "   Fold 10 accuracy: 74.21 %\n",
      "     Overall test accuracy: 75.89 %\n",
      "     Overall training accuracy: 79.00 %\n",
      "model 8: SVM RBF Gamma=2.000 C=4.00\n",
      "   Fold 1 accuracy: 72.63 %\n",
      "   Fold 2 accuracy: 82.11 %\n",
      "   Fold 3 accuracy: 82.63 %\n",
      "   Fold 4 accuracy: 78.42 %\n",
      "   Fold 5 accuracy: 73.68 %\n",
      "   Fold 6 accuracy: 80.53 %\n",
      "   Fold 7 accuracy: 84.21 %\n",
      "   Fold 8 accuracy: 76.84 %\n",
      "   Fold 9 accuracy: 73.16 %\n",
      "   Fold 10 accuracy: 74.74 %\n",
      "     Overall test accuracy: 77.89 %\n",
      "     Overall training accuracy: 81.26 %\n",
      "model 9: SVM RBF Gamma=2.000 C=6.00\n",
      "   Fold 1 accuracy: 79.47 %\n",
      "   Fold 2 accuracy: 77.37 %\n",
      "   Fold 3 accuracy: 78.95 %\n",
      "   Fold 4 accuracy: 77.37 %\n",
      "   Fold 5 accuracy: 80.53 %\n",
      "   Fold 6 accuracy: 81.05 %\n",
      "   Fold 7 accuracy: 77.89 %\n",
      "   Fold 8 accuracy: 72.11 %\n",
      "   Fold 9 accuracy: 75.26 %\n",
      "   Fold 10 accuracy: 80.53 %\n",
      "     Overall test accuracy: 78.05 %\n",
      "     Overall training accuracy: 82.26 %\n",
      "model 10: SVM RBF Gamma=2.000 C=8.00\n",
      "   Fold 1 accuracy: 74.21 %\n",
      "   Fold 2 accuracy: 76.32 %\n",
      "   Fold 3 accuracy: 76.84 %\n",
      "   Fold 4 accuracy: 74.74 %\n",
      "   Fold 5 accuracy: 85.79 %\n",
      "   Fold 6 accuracy: 81.05 %\n",
      "   Fold 7 accuracy: 83.16 %\n",
      "   Fold 8 accuracy: 77.89 %\n",
      "   Fold 9 accuracy: 81.05 %\n",
      "   Fold 10 accuracy: 82.63 %\n",
      "     Overall test accuracy: 79.37 %\n",
      "     Overall training accuracy: 83.47 %\n",
      "model 11: SVM RBF Gamma=2.000 C=10.00\n",
      "   Fold 1 accuracy: 78.42 %\n",
      "   Fold 2 accuracy: 79.47 %\n",
      "   Fold 3 accuracy: 80.00 %\n",
      "   Fold 4 accuracy: 81.05 %\n",
      "   Fold 5 accuracy: 75.26 %\n",
      "   Fold 6 accuracy: 83.68 %\n",
      "   Fold 7 accuracy: 80.00 %\n",
      "   Fold 8 accuracy: 82.11 %\n",
      "   Fold 9 accuracy: 77.37 %\n",
      "   Fold 10 accuracy: 77.89 %\n",
      "     Overall test accuracy: 79.53 %\n",
      "     Overall training accuracy: 84.05 %\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# SVM\n",
    "model = 0\n",
    "cont = []\n",
    "results = pd.DataFrame(columns=('name', 'accuracy'))\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "C = [1,2,4,6,8,10]\n",
    "gamma = [1,2]  \n",
    "for g in range(len(gamma)):\n",
    "    acc = []\n",
    "    name = \"SVM RBF Gamma=%.3f\" % (gamma[g])     \n",
    "    for c in range(len(C)):\n",
    "        fold = 1\n",
    "        truth = []\n",
    "        svm_prediction = []\n",
    "        print(\"model %d: SVM RBF Gamma=%.3f C=%.2f\" % (model, gamma[g], C[c]))        \n",
    "        test_count = 0\n",
    "        svm = SVC(C=C[c], kernel='rbf', gamma=gamma[g])\n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            trainX = X[train_idx]\n",
    "            trainY = Y[train_idx]\n",
    "            testX = X[test_idx]\n",
    "            testY = Y[test_idx]\n",
    "            truth.append(testY)\n",
    "            svm.fit(trainX, trainY)\n",
    "            Y_hat = svm.predict(testX)\n",
    "            svm_prediction.append(Y_hat)\n",
    "            print(\"   Fold %d accuracy: %.2f %%\" % (fold, ((np.sum(Y_hat == testY)/len(testY)) * 100.0)))                        \n",
    "            fold += 1\n",
    "        truth = np.concatenate(truth, axis=0)    \n",
    "        svm_prediction = np.concatenate(svm_prediction, axis=0)\n",
    "        test_results = np.sum(svm_prediction == truth)/len(truth)\n",
    "        print(\"     Overall test accuracy: %.2f %%\" % (test_results * 100))  \n",
    "        svm = svm.fit(X, Y)\n",
    "        Y_hat = svm.predict(X)\n",
    "        train_results = np.sum(Y_hat == Y)/len(Y)\n",
    "        print(\"     Overall training accuracy: %.2f %%\" % (train_results * 100.0))  \n",
    "        acc.append([train_results, test_results])   \n",
    "        cont.append([truth, svm_prediction])\n",
    "        model += 1\n",
    "    results = results.append({'name': name, 'accuracy' : acc}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n",
      "vm  0.6702439024390244\n",
      "vn  0.7804878048780488\n",
      "nlp\n",
      "precision:  0.7890410958904109\n",
      "recall:  0.6605504587155964\n",
      "F1:  0.7191011235955057\n",
      "nlp0\n",
      "precision:  0.7757575757575758\n",
      "recall:  0.8692699490662139\n",
      "F1:  0.7191011235955057\n",
      "ave\n",
      "precision:  0.7823993358239933\n",
      "recall:  0.7649102038909051\n",
      "F1:  0.7191011235955057\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C=10, kernel='rbf', gamma=2) #79.2%\n",
    "#svm = SVC(C=2, kernel='rbf', gamma=128) #79.6\n",
    "#svm = SVC(C=2, kernel='rbf', gamma=128) \n",
    "train_num = 1\n",
    "for i in range(train_num):\n",
    "    svm.fit(X, Y)\n",
    "    Y2_hat = svm.predict(X2)\n",
    "    vm = np.sum(Y2_hat == Ym2)/len(Ym2)\n",
    "    vn = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "    print(np.sum(Y2_hat))\n",
    "    print(\"vm \", vm)\n",
    "    print(\"vn \",vn)\n",
    "    \n",
    "precision = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2)-np.sum(Y2))\n",
    "f10 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp0\")\n",
    "print(\"precision: \", precision0)\n",
    "print(\"recall: \", recall0)\n",
    "print(\"F1: \", f10)\n",
    "\n",
    "print(\"ave\")\n",
    "print(\"precision: \", (precision+precision0)/2)\n",
    "print(\"recall: \", (recall+recall0)/2)\n",
    "print(\"F1: \", (f1+f10)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Best Model: 11\n",
      "\n",
      "SVM\n",
      "          no  social  Total\n",
      "no       987     280   1267\n",
      "social   109     524    633\n",
      "Total   1096     804   1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "model = input(\"Enter Best Model: \")\n",
    "best = cont[int(model)]\n",
    "rf_ct = pd.crosstab(best[1], best[0], margins=True)\n",
    "rf_ct.columns = [\"no\", \"social\", \"Total\"]\n",
    "rf_ct.index = [\"no\", \"social\", \"Total\"]\n",
    "print()\n",
    "print(\"SVM\")\n",
    "print(rf_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Sensitivity: 0.65174 Specificity: 0.90055 PPV: 0.82780 NPV: 0.77901 Accuracy: 0.79526\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "Sens = rf_ct.iloc[1][1]/rf_ct.iloc[2][1]\n",
    "Spec = rf_ct.iloc[0][0]/rf_ct.iloc[2][0]\n",
    "PPV = rf_ct.iloc[1][1]/rf_ct.iloc[1][2]\n",
    "NPV = rf_ct.iloc[0][0]/rf_ct.iloc[0][2]\n",
    "ACC = (rf_ct.iloc[0][0] + rf_ct.iloc[1][1]) / rf_ct.iloc[2][2]\n",
    "print(\"Random Forest: Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[987 109]\n",
      " [280 524]]\n",
      "0.7292971468336812\n",
      "0.6517412935323383\n",
      "0.8278041074249605\n",
      "0.7952631578947369\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.90      0.84      1096\n",
      "          1       0.83      0.65      0.73       804\n",
      "\n",
      "avg / total       0.80      0.80      0.79      1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,classification_report\n",
    "y_true =cont[int(model)][0]\n",
    "y_pred = cont[int(model)][1]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred) )\n",
    "\n",
    "print(recall_score(y_true, y_pred),   )\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  0 : Random Forest trees = 5\n",
      "   Fold 1 accuracy: 71.58 %\n",
      "   Fold 2 accuracy: 79.47 %\n",
      "   Fold 3 accuracy: 73.16 %\n",
      "   Fold 4 accuracy: 74.74 %\n",
      "   Fold 5 accuracy: 71.58 %\n",
      "   Fold 6 accuracy: 76.84 %\n",
      "   Fold 7 accuracy: 75.26 %\n",
      "   Fold 8 accuracy: 80.00 %\n",
      "   Fold 9 accuracy: 73.68 %\n",
      "   Fold 10 accuracy: 77.37 %\n",
      "     Overall test accuracy: 75.37 %\n",
      "     Overall training accuracy: 98.11 %\n",
      "model  1 : Random Forest trees = 10\n",
      "   Fold 1 accuracy: 74.74 %\n",
      "   Fold 2 accuracy: 76.32 %\n",
      "   Fold 3 accuracy: 78.95 %\n",
      "   Fold 4 accuracy: 77.37 %\n",
      "   Fold 5 accuracy: 73.16 %\n",
      "   Fold 6 accuracy: 71.58 %\n",
      "   Fold 7 accuracy: 78.95 %\n",
      "   Fold 8 accuracy: 77.37 %\n",
      "   Fold 9 accuracy: 70.00 %\n",
      "   Fold 10 accuracy: 76.32 %\n",
      "     Overall test accuracy: 75.47 %\n",
      "     Overall training accuracy: 99.26 %\n",
      "model  2 : Random Forest trees = 50\n",
      "   Fold 1 accuracy: 81.58 %\n",
      "   Fold 2 accuracy: 78.42 %\n",
      "   Fold 3 accuracy: 83.68 %\n",
      "   Fold 4 accuracy: 78.95 %\n",
      "   Fold 5 accuracy: 76.84 %\n",
      "   Fold 6 accuracy: 79.47 %\n",
      "   Fold 7 accuracy: 83.16 %\n",
      "   Fold 8 accuracy: 83.16 %\n",
      "   Fold 9 accuracy: 80.53 %\n",
      "   Fold 10 accuracy: 78.95 %\n",
      "     Overall test accuracy: 80.47 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  3 : Random Forest trees = 100\n",
      "   Fold 1 accuracy: 83.16 %\n",
      "   Fold 2 accuracy: 77.37 %\n",
      "   Fold 3 accuracy: 81.05 %\n",
      "   Fold 4 accuracy: 82.11 %\n",
      "   Fold 5 accuracy: 78.95 %\n",
      "   Fold 6 accuracy: 81.58 %\n",
      "   Fold 7 accuracy: 77.89 %\n",
      "   Fold 8 accuracy: 78.95 %\n",
      "   Fold 9 accuracy: 87.37 %\n",
      "   Fold 10 accuracy: 81.05 %\n",
      "     Overall test accuracy: 80.95 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  4 : Random Forest trees = 200\n",
      "   Fold 1 accuracy: 82.63 %\n",
      "   Fold 2 accuracy: 81.05 %\n",
      "   Fold 3 accuracy: 83.68 %\n",
      "   Fold 4 accuracy: 81.58 %\n",
      "   Fold 5 accuracy: 81.58 %\n",
      "   Fold 6 accuracy: 81.58 %\n",
      "   Fold 7 accuracy: 84.74 %\n",
      "   Fold 8 accuracy: 82.11 %\n",
      "   Fold 9 accuracy: 75.79 %\n",
      "   Fold 10 accuracy: 77.37 %\n",
      "     Overall test accuracy: 81.21 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  5 : Random Forest trees = 300\n",
      "   Fold 1 accuracy: 81.58 %\n",
      "   Fold 2 accuracy: 83.16 %\n",
      "   Fold 3 accuracy: 78.95 %\n",
      "   Fold 4 accuracy: 75.26 %\n",
      "   Fold 5 accuracy: 78.95 %\n",
      "   Fold 6 accuracy: 82.63 %\n",
      "   Fold 7 accuracy: 82.11 %\n",
      "   Fold 8 accuracy: 81.05 %\n",
      "   Fold 9 accuracy: 82.11 %\n",
      "   Fold 10 accuracy: 79.47 %\n",
      "     Overall test accuracy: 80.53 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  6 : Random Forest trees = 400\n",
      "   Fold 1 accuracy: 82.11 %\n",
      "   Fold 2 accuracy: 79.47 %\n",
      "   Fold 3 accuracy: 84.74 %\n",
      "   Fold 4 accuracy: 77.37 %\n",
      "   Fold 5 accuracy: 80.53 %\n",
      "   Fold 6 accuracy: 77.89 %\n",
      "   Fold 7 accuracy: 83.68 %\n",
      "   Fold 8 accuracy: 80.00 %\n",
      "   Fold 9 accuracy: 80.00 %\n",
      "   Fold 10 accuracy: 80.53 %\n",
      "     Overall test accuracy: 80.63 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  7 : Random Forest trees = 500\n",
      "   Fold 1 accuracy: 81.05 %\n",
      "   Fold 2 accuracy: 80.00 %\n",
      "   Fold 3 accuracy: 82.11 %\n",
      "   Fold 4 accuracy: 81.58 %\n",
      "   Fold 5 accuracy: 83.68 %\n",
      "   Fold 6 accuracy: 78.95 %\n",
      "   Fold 7 accuracy: 82.63 %\n",
      "   Fold 8 accuracy: 82.11 %\n",
      "   Fold 9 accuracy: 76.32 %\n",
      "   Fold 10 accuracy: 82.63 %\n",
      "     Overall test accuracy: 81.11 %\n",
      "     Overall training accuracy: 100.00 %\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# RandomForest\n",
    "model=0\n",
    "results = []\n",
    "cont = []\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "trees = [5, 10, 50, 100, 200, 300, 400, 500]\n",
    "for t in range(len(trees)):\n",
    "    fold = 1\n",
    "    truth = []\n",
    "    rf_prediction = []\n",
    "    print(\"model \", t, \": Random Forest trees = \" + str(trees[t]))\n",
    "    test_count = 0\n",
    "    rf = RandomForestClassifier(n_estimators=trees[t], criterion='entropy', n_jobs=-1, )\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        trainX = X[train_idx]\n",
    "        trainY = Y[train_idx]\n",
    "        testX = X[test_idx]\n",
    "        testY = Y[test_idx]\n",
    "        truth.append(testY)\n",
    "        rf.fit(trainX, trainY)\n",
    "        Y_hat = rf.predict(testX)\n",
    "        rf_prediction.append(Y_hat)\n",
    "        print(\"   Fold %d accuracy: %.2f %%\" % (fold, ((np.sum(Y_hat == testY)/len(testY)) * 100.0)))                        \n",
    "        fold += 1\n",
    "    truth = np.concatenate(truth, axis=0)    \n",
    "    rf_prediction = np.concatenate(rf_prediction, axis=0)\n",
    "    test_results = np.sum(rf_prediction == truth)/len(truth)\n",
    "    print(\"     Overall test accuracy: %.2f %%\" % (test_results * 100))  \n",
    "    rf = rf.fit(X, Y)\n",
    "    Y_hat = rf.predict(X)\n",
    "    train_results = np.sum(Y_hat == Y)/len(Y)\n",
    "    print(\"     Overall training accuracy: %.2f %%\" % (train_results * 100.0))  \n",
    "    results.append([train_results, test_results])   \n",
    "    cont.append([truth, rf_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "vm  0.646829268292683\n",
      "vn  0.7824390243902439\n",
      "nlp\n",
      "precision:  0.7482517482517482\n",
      "recall:  0.7362385321100917\n",
      "F1:  0.7421965317919075\n",
      "nlp0\n",
      "precision:  0.8070469798657718\n",
      "recall:  0.8166383701188455\n",
      "F1:  0.7421965317919075\n",
      "ave\n",
      "precision:  0.7776493640587601\n",
      "recall:  0.7764384511144686\n",
      "F1:  0.7421965317919075\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, criterion='entropy', n_jobs=-1, )\n",
    "train_num = 1\n",
    "for i in range(train_num):\n",
    "    rf.fit(X, Y)\n",
    "    Y2_hat = rf.predict(X2)\n",
    "    vm = np.sum(Y2_hat == Ym2)/len(Ym2)\n",
    "    vn = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "    print(np.sum(Y2_hat))\n",
    "    print(\"vm \", vm)\n",
    "    print(\"vn \",vn)\n",
    "    \n",
    "precision = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2)-np.sum(Y2))\n",
    "f10 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp0\")\n",
    "print(\"precision: \", precision0)\n",
    "print(\"recall: \", recall0)\n",
    "print(\"F1: \", f10)\n",
    "\n",
    "print(\"ave\")\n",
    "print(\"precision: \", (precision+precision0)/2)\n",
    "print(\"recall: \", (recall+recall0)/2)\n",
    "print(\"F1: \", (f1+f10)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Best Model: 4\n",
      "\n",
      "Random Forest\n",
      "          no  social  Total\n",
      "no       941     202   1143\n",
      "social   155     602    757\n",
      "Total   1096     804   1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "model = input(\"Enter Best Model: \")\n",
    "best = cont[int(model)]\n",
    "rf_ct = pd.crosstab(best[1], best[0], margins=True)\n",
    "rf_ct.columns = [\"no\", \"social\", \"Total\"]\n",
    "rf_ct.index = [\"no\", \"social\", \"Total\"]\n",
    "print()\n",
    "print(\"Random Forest\")\n",
    "print(rf_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Sensitivity: 0.74876 Specificity: 0.85858 PPV: 0.79524 NPV: 0.82327 Accuracy: 0.81211\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "Sens = rf_ct.iloc[1][1]/rf_ct.iloc[2][1]\n",
    "Spec = rf_ct.iloc[0][0]/rf_ct.iloc[2][0]\n",
    "PPV = rf_ct.iloc[1][1]/rf_ct.iloc[1][2]\n",
    "NPV = rf_ct.iloc[0][0]/rf_ct.iloc[0][2]\n",
    "ACC = (rf_ct.iloc[0][0] + rf_ct.iloc[1][1]) / rf_ct.iloc[2][2]\n",
    "print(\"Random Forest: Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[941 155]\n",
      " [202 602]]\n",
      "0.7713004484304932\n",
      "0.7487562189054726\n",
      "0.7952443857331571\n",
      "0.8121052631578948\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.86      0.84      1096\n",
      "          1       0.80      0.75      0.77       804\n",
      "\n",
      "avg / total       0.81      0.81      0.81      1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,classification_report\n",
    "y_true =cont[int(model)][0]\n",
    "y_pred = cont[int(model)][1]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred) )\n",
    "\n",
    "\n",
    "\n",
    "print(recall_score(y_true, y_pred),   )\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.913158\n",
      "Test set score: 0.801951\n",
      "precision:  0.7890818858560794\n",
      "recall:  0.7293577981651376\n",
      "F1:  0.7580452920143027\n",
      "precision:  0.8102893890675241\n",
      "recall:  0.8556876061120543\n",
      "F1:  0.8323699421965317\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#from sklearn.utils import shuffle\n",
    "#X, Y = shuffle(X, Y)\n",
    "#split = int(len(Y) * 4/5)\n",
    "#trainX = X[:split, :]\n",
    "#trainY = Y[:split]\n",
    "#testX = X[split:, :]\n",
    "#testY = Y[split:]\n",
    "trainX = X\n",
    "trainY = Y\n",
    "testX = X2\n",
    "testY = Y2\n",
    "\n",
    "#%%\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, alpha=1e-4,\n",
    "                    solver='adam', verbose=False, tol=1e-4, random_state=1)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4,\n",
    "#                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "#                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(trainX, trainY)\n",
    "print(\"Training set score: %f\" % mlp.score(trainX, trainY))\n",
    "print(\"Test set score: %f\" % mlp.score(testX, testY))\n",
    "y_hat = mlp.predict(testX)\n",
    "precision = np.sum(y_hat + testY == 2)/np.sum(y_hat)\n",
    "recall = np.sum(y_hat + testY == 2)/np.sum(testY)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision = np.sum(y_hat + testY == 0)/(len(y_hat)-np.sum(y_hat))\n",
    "recall = np.sum(y_hat + testY == 0)/(len(testY)-np.sum(testY))\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.914737\n",
      "Test set score: 0.797073\n",
      "precision:  0.7780487804878049\n",
      "recall:  0.731651376146789\n",
      "F1:  0.7541371158392435\n",
      "precision:  0.8097560975609757\n",
      "recall:  0.8455008488964346\n",
      "F1:  0.8272425249169436\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "trainX = X\n",
    "trainY = Y\n",
    "testX = X2\n",
    "testY = Y2\n",
    "\n",
    "#%%\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,),max_iter=500, alpha=1e-4)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(100,),max_iter=1000, alpha=1e-4) 67.5%\n",
    "\n",
    "mlp.fit(trainX, trainY)\n",
    "print(\"Training set score: %f\" % mlp.score(trainX, trainY))\n",
    "print(\"Test set score: %f\" % mlp.score(testX, testY))\n",
    "y_hat = mlp.predict(testX)\n",
    "precision = np.sum(y_hat + testY == 2)/np.sum(y_hat)\n",
    "recall = np.sum(y_hat + testY == 2)/np.sum(testY)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision = np.sum(y_hat + testY == 0)/(len(y_hat)-np.sum(y_hat))\n",
    "recall = np.sum(y_hat + testY == 0)/(len(testY)-np.sum(testY))\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.925263\n",
      "Test set score: 0.797073\n",
      "precision:  0.7766990291262136\n",
      "recall:  0.7339449541284404\n",
      "F1:  0.7547169811320755\n",
      "precision:  0.8107667210440457\n",
      "recall:  0.8438030560271647\n",
      "F1:  0.8269550748752079\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "trainX = X\n",
    "trainY = Y\n",
    "testX = X2\n",
    "testY = Y2\n",
    "\n",
    "#%%\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(300,),max_iter=500, alpha=1e-4)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(100,),max_iter=1000, alpha=1e-4) 67.5%\n",
    "\n",
    "mlp.fit(trainX, trainY)\n",
    "print(\"Training set score: %f\" % mlp.score(trainX, trainY))\n",
    "print(\"Test set score: %f\" % mlp.score(testX, testY))\n",
    "y_hat = mlp.predict(testX)\n",
    "precision = np.sum(y_hat + testY == 2)/np.sum(y_hat)\n",
    "recall = np.sum(y_hat + testY == 2)/np.sum(testY)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision = np.sum(y_hat + testY == 0)/(len(y_hat)-np.sum(y_hat))\n",
    "recall = np.sum(y_hat + testY == 0)/(len(testY)-np.sum(testY))\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive_bayes GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_new[:1900]\n",
    "X2 = X_new[1900:]\n",
    "Y = Yn[:1900]\n",
    "Y2 = Yn[1900:]\n",
    "Ym1 = Ym[:1900]\n",
    "Ym2 = Ym[1900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.823684\n",
      "Test set score: 0.761951\n",
      "precision:  0.8221476510067114\n",
      "recall:  0.5619266055045872\n",
      "F1:  0.6675749318801091\n",
      "precision:  0.7372764786795049\n",
      "recall:  0.9100169779286927\n",
      "F1:  0.8145896656534954\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainX = X.todense()\n",
    "testX = X2.todense()\n",
    "trainY = Y\n",
    "testY = Y2\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(trainX, trainY)\n",
    "\n",
    "print(\"Training set score: %f\" % gnb.score(trainX, trainY))\n",
    "print(\"Test set score: %f\" % gnb.score(testX, testY))\n",
    "y_hat = gnb.predict(testX)\n",
    "precision = np.sum(y_hat + testY == 2)/np.sum(y_hat)\n",
    "recall = np.sum(y_hat + testY == 2)/np.sum(testY)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision = np.sum(y_hat + testY == 0)/(len(y_hat)-np.sum(y_hat))\n",
    "recall = np.sum(y_hat + testY == 0)/(len(testY)-np.sum(testY))\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.793684\n",
      "Test set score: 0.765854\n",
      "precision:  0.748730964467005\n",
      "recall:  0.676605504587156\n",
      "F1:  0.7108433734939759\n",
      "precision:  0.7765451664025357\n",
      "recall:  0.831918505942275\n",
      "F1:  0.8032786885245902\n"
     ]
    }
   ],
   "source": [
    "trainX = X.todense()\n",
    "testX = X2.todense()\n",
    "trainY = Y\n",
    "testY = Y2\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(trainX, trainY)\n",
    "\n",
    "print(\"Training set score: %f\" % bnb.score(trainX, trainY))\n",
    "print(\"Test set score: %f\" % bnb.score(testX, testY))\n",
    "y_hat = bnb.predict(testX)\n",
    "precision = np.sum(y_hat + testY == 2)/np.sum(y_hat)\n",
    "recall = np.sum(y_hat + testY == 2)/np.sum(testY)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision = np.sum(y_hat + testY == 0)/(len(y_hat)-np.sum(y_hat))\n",
    "recall = np.sum(y_hat + testY == 0)/(len(testY)-np.sum(testY))\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.580526\n",
      "Test set score: 0.575610\n",
      "precision:  1.0\n",
      "recall:  0.0022935779816513763\n",
      "F1:  0.004576659038901603\n",
      "precision:  0.5751953125\n",
      "recall:  1.0\n",
      "F1:  0.7303161810291382\n"
     ]
    }
   ],
   "source": [
    "trainX = X.todense()\n",
    "testX = X2.todense()\n",
    "trainY = Y\n",
    "testY = Y2\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(trainX, trainY)\n",
    "\n",
    "print(\"Training set score: %f\" % mnb.score(trainX, trainY))\n",
    "print(\"Test set score: %f\" % mnb.score(testX, testY))\n",
    "y_hat = mnb.predict(testX)\n",
    "precision = np.sum(y_hat + testY == 2)/np.sum(y_hat)\n",
    "recall = np.sum(y_hat + testY == 2)/np.sum(testY)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision = np.sum(y_hat + testY == 0)/(len(y_hat)-np.sum(y_hat))\n",
    "recall = np.sum(y_hat + testY == 0)/(len(testY)-np.sum(testY))\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
