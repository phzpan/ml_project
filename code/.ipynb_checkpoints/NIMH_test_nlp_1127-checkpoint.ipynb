{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIMH Project - Machine Learning - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import math\n",
    "import chardet\n",
    "os.chdir('Z:\\project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pat_visit</th>\n",
       "      <th>m1</th>\n",
       "      <th>n1</th>\n",
       "      <th>txt1</th>\n",
       "      <th>m2</th>\n",
       "      <th>n2</th>\n",
       "      <th>txt2</th>\n",
       "      <th>fsize</th>\n",
       "      <th>m1_1</th>\n",
       "      <th>n1_1</th>\n",
       "      <th>m2_1</th>\n",
       "      <th>n2_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12115408_2404622</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>MRN:                     12115408\\r\\n...... Me...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MRN:                     12115408\\r\\n...... Me...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5164967_190590119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MRN: 5164967\\r\\n...... MRN: 5164967\\r\\n...... ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MRN: 5164967\\r\\n...... MRN: 5164967\\r\\n...... ...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12115408_2410892</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>MRN:                12115408\\r\\n...... MEDICAL...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MRN:                12115408\\r\\n...... MEDICAL...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12115408_2454221</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>MRN:                     12115408\\r\\n...... Me...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>MRN:                     12115408\\r\\n...... Me...</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11307451_2237089</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>MRN:                     11307451\\r\\n...... MR...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>MRN:                     11307451\\r\\n...... MR...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0          pat_visit  m1  n1  \\\n",
       "0           0   12115408_2404622   1   0   \n",
       "1           1  5164967_190590119   1   1   \n",
       "2           2   12115408_2410892   1   1   \n",
       "3           3   12115408_2454221   1   2   \n",
       "4           4   11307451_2237089   1   4   \n",
       "\n",
       "                                                txt1  m2  n2  \\\n",
       "0  MRN:                     12115408\\r\\n...... Me...   0   1   \n",
       "1  MRN: 5164967\\r\\n...... MRN: 5164967\\r\\n...... ...   0   1   \n",
       "2  MRN:                12115408\\r\\n...... MEDICAL...   0   1   \n",
       "3  MRN:                     12115408\\r\\n...... Me...   0   2   \n",
       "4  MRN:                     11307451\\r\\n...... MR...   0   3   \n",
       "\n",
       "                                                txt2  fsize  m1_1  n1_1  m2_1  \\\n",
       "0  MRN:                     12115408\\r\\n...... Me...     12     0     0     0   \n",
       "1  MRN: 5164967\\r\\n...... MRN: 5164967\\r\\n...... ...     12     0     0     0   \n",
       "2  MRN:                12115408\\r\\n...... MEDICAL...     13     0     0     0   \n",
       "3  MRN:                     12115408\\r\\n...... Me...     12     0     0     0   \n",
       "4  MRN:                     11307451\\r\\n...... MR...     32     0     0     0   \n",
       "\n",
       "   n2_1  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "#data = pd.read_csv(\"./results/pat_visit_score_match_1127.csv\")\n",
    "data = pd.read_csv(\"./results/train_1885.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1885, 13)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pat_visit</th>\n",
       "      <th>m1</th>\n",
       "      <th>n1</th>\n",
       "      <th>txt1</th>\n",
       "      <th>m2</th>\n",
       "      <th>n2</th>\n",
       "      <th>txt2</th>\n",
       "      <th>fsize</th>\n",
       "      <th>m1_1</th>\n",
       "      <th>n1_1</th>\n",
       "      <th>m2_1</th>\n",
       "      <th>n2_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>718</td>\n",
       "      <td>10399566_2070498</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>MRN:                     10399566\\r\\n...... Me...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>MRN:                     10399566\\r\\n...... Me...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>716</td>\n",
       "      <td>8933772_190282440</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>MRN:  08933772           ...... MRN: 8933772\\r...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>MRN:  08933772           ...... MRN: 8933772\\r...</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>977</td>\n",
       "      <td>20323517_185871860</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>MRN: 20323517\\r\\n...... MRN: 20323517\\r\\n........</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>MRN: 20323517\\r\\n...... MRN: 20323517\\r\\n........</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>1723</td>\n",
       "      <td>9446261_188526717</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>MRN: 9446261\\r\\n...... MRN: 9446261\\r\\n...... ...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>MRN: 9446261\\r\\n...... MRN: 9446261\\r\\n...... ...</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1440</td>\n",
       "      <td>12164331_185732698</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>MRN: 12164331\\r\\n...... MRN: 12164331\\r\\n........</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>MRN: 12164331\\r\\n...... MRN: 12164331\\r\\n........</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0           pat_visit  m1  n1  \\\n",
       "718          718    10399566_2070498   4   4   \n",
       "716          716   8933772_190282440   4   4   \n",
       "977          977  20323517_185871860   5   9   \n",
       "1723        1723   9446261_188526717   9  20   \n",
       "1440        1440  12164331_185732698   7   4   \n",
       "\n",
       "                                                   txt1  m2  n2  \\\n",
       "718   MRN:                     10399566\\r\\n...... Me...   3   3   \n",
       "716   MRN:  08933772           ...... MRN: 8933772\\r...   3   3   \n",
       "977   MRN: 20323517\\r\\n...... MRN: 20323517\\r\\n........   3   3   \n",
       "1723  MRN: 9446261\\r\\n...... MRN: 9446261\\r\\n...... ...   5   9   \n",
       "1440  MRN: 12164331\\r\\n...... MRN: 12164331\\r\\n........   4   1   \n",
       "\n",
       "                                                   txt2  fsize  m1_1  n1_1  \\\n",
       "718   MRN:                     10399566\\r\\n...... Me...     19     0     0   \n",
       "716   MRN:  08933772           ...... MRN: 8933772\\r...     35     0     0   \n",
       "977   MRN: 20323517\\r\\n...... MRN: 20323517\\r\\n........     34     1     1   \n",
       "1723  MRN: 9446261\\r\\n...... MRN: 9446261\\r\\n...... ...     56     1     1   \n",
       "1440  MRN: 12164331\\r\\n...... MRN: 12164331\\r\\n........     24     1     0   \n",
       "\n",
       "      m2_1  n2_1  \n",
       "718      1     1  \n",
       "716      1     1  \n",
       "977      1     1  \n",
       "1723     1     1  \n",
       "1440     1     0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data = shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelm=data[data.columns[9]].tolist()\n",
    "labeln=data[data.columns[10]].tolist()\n",
    "labelm2=data[data.columns[11]].tolist()\n",
    "labeln2=data[data.columns[12]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5506631299734748, 0.5358090185676393)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_m1 = np.array(labelm)\n",
    "arr_n1 = np.array(labeln)\n",
    "arr_m2 = np.array(labelm2)\n",
    "arr_n2 = np.array(labeln2)\n",
    "sum(arr_m1 == arr_n1)/len(arr_m1), sum(arr_m2 == arr_n2)/len(arr_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "corpusList=data[data.columns[4]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusList2=data[data.columns[7]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1885"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpusList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1885"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpusList2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def tokenize(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = [ token for token in tokens if re.search('(^[a-zA-Z]+$)', token) ]\n",
    "    a=[]\n",
    "    for i in filtered_tokens:\n",
    "        a.append(WordNetLemmatizer().lemmatize(i,'v'))\n",
    "    return a\n",
    "    #return filtered_tokens\n",
    "\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1885, 2461089)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "cv = TfidfVectorizer(lowercase=True,\n",
    "                     ngram_range=(1, 4), preprocessor=None, stop_words='english',\n",
    "                     strip_accents=None, tokenizer=tokenize, vocabulary=None)\n",
    "X1 = cv.fit_transform(corpusList)\n",
    "lexicon = cv.get_feature_names()\n",
    "#print (lexicon)\n",
    "print()\n",
    "\n",
    "#%%\n",
    "x=X1  ## for select fetures \n",
    "print(x.shape)\n",
    "\n",
    "pkl.dump( x, open( \"./results/tfidf_1885.pickle\", \"wb\" ) )\n",
    "pkl.dump( lexicon, open( \"./results/lexicon_1885.pickle\", \"wb\" ) )\n",
    "#x1 = pkl.load( open( \"./results/tfidf_4801395.pickle\", \"rb\" ) )\n",
    "#lexicon1 = pkl.load( open( \"./results/lexicon_4801395.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1885, 1826545)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "cv2 = TfidfVectorizer(lowercase=True,\n",
    "                     ngram_range=(1, 4), preprocessor=None, stop_words='english',\n",
    "                     strip_accents=None, tokenizer=tokenize, vocabulary=None)\n",
    "X2 = cv2.fit_transform(corpusList2)\n",
    "lexicon2 = cv2.get_feature_names()\n",
    "#print (lexicon)\n",
    "print()\n",
    "\n",
    "#%%\n",
    "x2=X2  ## for select fetures \n",
    "print(x2.shape)\n",
    "\n",
    "pkl.dump( x2, open( \"./results/tfidf_1885_2.pickle\", \"wb\" ) )\n",
    "pkl.dump( lexicon2, open( \"./results/lexicon_1885_2.pickle\", \"wb\" ) )\n",
    "#x1 = pkl.load( open( \"./results/tfidf_4801395.pickle\", \"rb\" ) )\n",
    "#lexicon1 = pkl.load( open( \"./results/lexicon_4801395.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ym = np.array(labelm)\n",
    "Yn = np.array(labeln)\n",
    "Ym2 = np.array(labelm2)\n",
    "Yn2 = np.array(labeln2)\n",
    "pkl.dump( Ym, open( \"./results/ym_1885.pickle\", \"wb\" ) )\n",
    "pkl.dump( Yn, open( \"./results/yn_1885.pickle\", \"wb\" ) )\n",
    "pkl.dump( Ym2, open( \"./results/ym_1885_2.pickle\", \"wb\" ) )\n",
    "pkl.dump( Yn2, open( \"./results/yn_1885_2.pickle\", \"wb\" ) )\n",
    "#print(Y)  ## class level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#%%\n",
    "#test\n",
    "cvt = TfidfVectorizer(lowercase=True,\n",
    "                     ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
    "                     strip_accents=None, tokenizer=tokenize, vocabulary=None)\n",
    "\n",
    "X1t = cvt.fit_transform(corpusList_test)\n",
    "print(X1t.shape)\n",
    "print()\n",
    "lexicon_test = cvt.get_feature_names()\n",
    "#print (lexicon)\n",
    "print()\n",
    "\n",
    "#%%\n",
    "xt=X1t  ## for select fetures \n",
    "print(xt.shape)\n",
    "\n",
    "Ym = np.array(labels_testm)\n",
    "Yn = np.array(labels_testn)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 0 1 0 1 1] [1 0 0 0 1 1 1 0 0 1] [1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1 1 1 0 0]\n",
      "[0 0 1 1 0 1 1 0 0 0] [0 0 0 1 0 1 1 0 1 0] [1 1 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0]\n",
      "[1 1 1 1 1 0 1 1 1 1] [1 1 0 1 1 1 1 1 0 1] [1 1 1 1 0 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1]\n",
      "[1 1 1 1 0 0 1 0 0 0] [0 1 1 1 1 1 1 0 1 0] [1 1 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(Ym[0:10], Ym[480:490], Ym[1865:])  ## class level\n",
    "print(Yn[0:10], Yn[480:490], Yn[1865:])  ## class level\n",
    "print(Ym2[0:10], Ym2[480:490], Ym2[1865:])  ## class level\n",
    "print(Yn2[0:10], Yn2[480:490], Yn2[1865:])  ## class level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1885, 800)\n"
     ]
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=800).fit_transform(x, Yn)   # select 800 features\n",
    "\n",
    "#%%\n",
    "X=X_new        # make unque name for next cell \n",
    "print(X.shape)\n",
    "#Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump( X, open( \"./results/tfidf_1885_800.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new2 = SelectKBest(chi2, k=800).fit_transform(x2, Yn2)\n",
    "pkl.dump( X_new2, open( \"./results/tfidf_1885_2_800.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pkl.load( open( \"./results/tfidf_1885_800.pickle\", \"rb\" ) )\n",
    "Ym = pkl.load( open( \"./results/ym_1885.pickle\", \"rb\" ) )\n",
    "Yn = pkl.load( open( \"./results/yn_1885.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_new[:1000]\n",
    "X2 = X_new[1000:]\n",
    "Y = Yn[:1000]\n",
    "Y2 = Yn[1000:]\n",
    "Ym1 = Ym[:1000]\n",
    "Ym2 = Ym[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1395, 600)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"X2_new = SelectKBest(chi2, k=600).fit_transform(xt, Ym)   # select 600 features\n",
    "X2_new.shape\n",
    "\n",
    "#%%\n",
    "X2=X2_new        # make unque name for next cell \n",
    "X2_new.shape\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  0 : ExtraTreesClassifier = 10\n",
      "   Fold 1 accuracy: 68.00 %\n",
      "   Fold 2 accuracy: 66.00 %\n",
      "   Fold 3 accuracy: 73.00 %\n",
      "   Fold 4 accuracy: 74.00 %\n",
      "   Fold 5 accuracy: 82.00 %\n",
      "   Fold 6 accuracy: 80.00 %\n",
      "   Fold 7 accuracy: 78.00 %\n",
      "   Fold 8 accuracy: 73.00 %\n",
      "   Fold 9 accuracy: 79.00 %\n",
      "   Fold 10 accuracy: 70.00 %\n",
      "     Overall test accuracy: 74.30 %\n",
      "     Overall training accuracy: 99.70 %\n",
      "model  1 : ExtraTreesClassifier = 30\n",
      "   Fold 1 accuracy: 81.00 %\n",
      "   Fold 2 accuracy: 78.00 %\n",
      "   Fold 3 accuracy: 67.00 %\n",
      "   Fold 4 accuracy: 75.00 %\n",
      "   Fold 5 accuracy: 79.00 %\n",
      "   Fold 6 accuracy: 79.00 %\n",
      "   Fold 7 accuracy: 75.00 %\n",
      "   Fold 8 accuracy: 75.00 %\n",
      "   Fold 9 accuracy: 77.00 %\n",
      "   Fold 10 accuracy: 78.00 %\n",
      "     Overall test accuracy: 76.40 %\n",
      "     Overall training accuracy: 99.70 %\n",
      "model  2 : ExtraTreesClassifier = 60\n",
      "   Fold 1 accuracy: 83.00 %\n",
      "   Fold 2 accuracy: 79.00 %\n",
      "   Fold 3 accuracy: 77.00 %\n",
      "   Fold 4 accuracy: 71.00 %\n",
      "   Fold 5 accuracy: 73.00 %\n",
      "   Fold 6 accuracy: 82.00 %\n",
      "   Fold 7 accuracy: 85.00 %\n",
      "   Fold 8 accuracy: 69.00 %\n",
      "   Fold 9 accuracy: 72.00 %\n",
      "   Fold 10 accuracy: 82.00 %\n",
      "     Overall test accuracy: 77.30 %\n",
      "     Overall training accuracy: 99.70 %\n",
      "model  3 : ExtraTreesClassifier = 100\n",
      "   Fold 1 accuracy: 78.00 %\n",
      "   Fold 2 accuracy: 80.00 %\n",
      "   Fold 3 accuracy: 75.00 %\n",
      "   Fold 4 accuracy: 75.00 %\n",
      "   Fold 5 accuracy: 76.00 %\n",
      "   Fold 6 accuracy: 71.00 %\n",
      "   Fold 7 accuracy: 78.00 %\n",
      "   Fold 8 accuracy: 80.00 %\n",
      "   Fold 9 accuracy: 75.00 %\n",
      "   Fold 10 accuracy: 74.00 %\n",
      "     Overall test accuracy: 76.20 %\n",
      "     Overall training accuracy: 99.60 %\n",
      "model  4 : ExtraTreesClassifier = 300\n",
      "   Fold 1 accuracy: 81.00 %\n",
      "   Fold 2 accuracy: 67.00 %\n",
      "   Fold 3 accuracy: 72.00 %\n",
      "   Fold 4 accuracy: 72.00 %\n",
      "   Fold 5 accuracy: 75.00 %\n",
      "   Fold 6 accuracy: 83.00 %\n",
      "   Fold 7 accuracy: 76.00 %\n",
      "   Fold 8 accuracy: 77.00 %\n",
      "   Fold 9 accuracy: 78.00 %\n",
      "   Fold 10 accuracy: 77.00 %\n",
      "     Overall test accuracy: 75.80 %\n",
      "     Overall training accuracy: 99.60 %\n",
      "model  5 : ExtraTreesClassifier = 500\n",
      "   Fold 1 accuracy: 76.00 %\n",
      "   Fold 2 accuracy: 68.00 %\n",
      "   Fold 3 accuracy: 75.00 %\n",
      "   Fold 4 accuracy: 79.00 %\n",
      "   Fold 5 accuracy: 81.00 %\n",
      "   Fold 6 accuracy: 87.00 %\n",
      "   Fold 7 accuracy: 74.00 %\n",
      "   Fold 8 accuracy: 79.00 %\n",
      "   Fold 9 accuracy: 79.00 %\n",
      "   Fold 10 accuracy: 72.00 %\n",
      "     Overall test accuracy: 77.00 %\n",
      "     Overall training accuracy: 99.80 %\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# ExtraTreesClassifier\n",
    "model=0\n",
    "results = []\n",
    "cont = []\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "trees = [10, 30, 60, 100, 300, 500]\n",
    "for t in range(len(trees)):\n",
    "    fold = 1\n",
    "    truth = []\n",
    "    rf_prediction = []\n",
    "    print(\"model \", t, \": ExtraTreesClassifier = \" + str(trees[t]))\n",
    "    test_count = 0\n",
    "    rf = ExtraTreesClassifier(bootstrap=False,\n",
    "           criterion='entropy', max_depth=15, max_features=0.9,\n",
    "           max_leaf_nodes=None, min_impurity_decrease=1e-045,\n",
    "           min_samples_leaf=1, min_samples_split=3,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=trees[t], n_jobs=-1,\n",
    "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        trainX = X[train_idx]\n",
    "        trainY = Y[train_idx]\n",
    "        testX = X[test_idx]\n",
    "        testY = Y[test_idx]\n",
    "        truth.append(testY)\n",
    "        rf.fit(trainX, trainY)\n",
    "        Y_hat = rf.predict(testX)\n",
    "        rf_prediction.append(Y_hat)\n",
    "        print(\"   Fold %d accuracy: %.2f %%\" % (fold, ((np.sum(Y_hat == testY)/len(testY)) * 100.0)))                        \n",
    "        fold += 1\n",
    "    truth = np.concatenate(truth, axis=0)    \n",
    "    rf_prediction = np.concatenate(rf_prediction, axis=0)\n",
    "    test_results = np.sum(rf_prediction == truth)/len(truth)\n",
    "    print(\"     Overall test accuracy: %.2f %%\" % (test_results * 100))  \n",
    "    rf = rf.fit(X, Y)\n",
    "    Y_hat = rf.predict(X)\n",
    "    train_results = np.sum(Y_hat == Y)/len(Y)\n",
    "    print(\"     Overall training accuracy: %.2f %%\" % (train_results * 100.0))  \n",
    "    results.append([train_results, test_results])   \n",
    "    cont.append([truth, rf_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ExtraTreesClassifier(bootstrap=False,\n",
    "       criterion='entropy', max_depth=15, max_features=0.9,\n",
    "       max_leaf_nodes=None, min_impurity_decrease=1e-045,\n",
    "       min_samples_leaf=1, min_samples_split=3,\n",
    "       min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=-1,      #trees[t] = 100\n",
    "       oob_score=False, random_state=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n",
      "vm  0.503954802259887\n",
      "vn  0.7604519774011299\n",
      "nlp\n",
      "precision:  0.7808219178082192\n",
      "recall:  0.6834532374100719\n",
      "F1:  0.7289002557544757\n",
      "nlp0\n",
      "precision:  0.7461538461538462\n",
      "recall:  0.8290598290598291\n",
      "F1:  0.7289002557544757\n",
      "ave\n",
      "precision:  0.7634878819810327\n",
      "recall:  0.7562565332349505\n",
      "F1:  0.7289002557544757\n"
     ]
    }
   ],
   "source": [
    "train_num = 1\n",
    "for i in range(train_num):\n",
    "    rf.fit(X, Y)\n",
    "    Y2_hat = rf.predict(X2)\n",
    "    vm = np.sum(Y2_hat == Ym2)/len(Ym2)\n",
    "    vn = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "    print(np.sum(Y2_hat))\n",
    "    print(\"vm \", vm)\n",
    "    print(\"vn \",vn)\n",
    "    \n",
    "precision = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2)-np.sum(Y2))\n",
    "f10 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp0\")\n",
    "print(\"precision: \", precision0)\n",
    "print(\"recall: \", recall0)\n",
    "print(\"F1: \", f10)\n",
    "\n",
    "print(\"ave\")\n",
    "print(\"precision: \", (precision+precision0)/2)\n",
    "print(\"recall: \", (recall+recall0)/2)\n",
    "print(\"F1: \", (f1+f10)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(885, 800)\n",
      "885\n"
     ]
    }
   ],
   "source": [
    "print(X2.shape)\n",
    "print(len(Y2_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Best Model: 2\n",
      "\n",
      "ExtraTrees\n",
      "         no  social  Total\n",
      "no      452     145    597\n",
      "social   82     321    403\n",
      "Total   534     466   1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "model = input(\"Enter Best Model: \")\n",
    "best = cont[int(model)]\n",
    "rf_ct = pd.crosstab(best[1], best[0], margins=True)\n",
    "rf_ct.columns = [\"no\", \"social\", \"Total\"]\n",
    "rf_ct.index = [\"no\", \"social\", \"Total\"]\n",
    "print()\n",
    "print(\"ExtraTrees\")\n",
    "print(rf_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[452  82]\n",
      " [145 321]]\n",
      "0.7387802071346375\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,classification_report\n",
    "y_true =cont[int(model)][0]\n",
    "y_pred = cont[int(model)][1]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6888412017167382\n",
      "0.7965260545905707\n",
      "0.773\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.85      0.80       534\n",
      "          1       0.80      0.69      0.74       466\n",
      "\n",
      "avg / total       0.78      0.77      0.77      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_true, y_pred),   )\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees: Sensitivity: 0.68884 Specificity: 0.84644 PPV: 0.79653 NPV: 0.75712 Accuracy: 0.77300\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "Sens = rf_ct.iloc[1][1]/rf_ct.iloc[2][1]\n",
    "Spec = rf_ct.iloc[0][0]/rf_ct.iloc[2][0]\n",
    "PPV = rf_ct.iloc[1][1]/rf_ct.iloc[1][2]\n",
    "NPV = rf_ct.iloc[0][0]/rf_ct.iloc[0][2]\n",
    "ACC = (rf_ct.iloc[0][0] + rf_ct.iloc[1][1]) / rf_ct.iloc[2][2]\n",
    "print(\"ExtraTrees: Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  0.7676415746411407\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(best[0], best[1], pos_label=1)\n",
    "roc_auc = auc(rf_fpr, rf_tpr)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(rf_fpr, rf_tpr, label='ExtraTrees')\n",
    "plt.xlabel('False positive rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(\"AUC = \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0: SVM RBF Gamma=1.000 C=1.00\n",
      "   Fold 1 accuracy: 65.00 %\n",
      "   Fold 2 accuracy: 76.00 %\n",
      "   Fold 3 accuracy: 72.00 %\n",
      "   Fold 4 accuracy: 72.00 %\n",
      "   Fold 5 accuracy: 66.00 %\n",
      "   Fold 6 accuracy: 74.00 %\n",
      "   Fold 7 accuracy: 68.00 %\n",
      "   Fold 8 accuracy: 71.00 %\n",
      "   Fold 9 accuracy: 76.00 %\n",
      "   Fold 10 accuracy: 73.00 %\n",
      "     Overall test accuracy: 71.30 %\n",
      "     Overall training accuracy: 72.60 %\n",
      "model 1: SVM RBF Gamma=1.000 C=2.00\n",
      "   Fold 1 accuracy: 71.00 %\n",
      "   Fold 2 accuracy: 73.00 %\n",
      "   Fold 3 accuracy: 77.00 %\n",
      "   Fold 4 accuracy: 75.00 %\n",
      "   Fold 5 accuracy: 75.00 %\n",
      "   Fold 6 accuracy: 70.00 %\n",
      "   Fold 7 accuracy: 72.00 %\n",
      "   Fold 8 accuracy: 72.00 %\n",
      "   Fold 9 accuracy: 73.00 %\n",
      "   Fold 10 accuracy: 79.00 %\n",
      "     Overall test accuracy: 73.70 %\n",
      "     Overall training accuracy: 75.90 %\n",
      "model 2: SVM RBF Gamma=1.000 C=4.00\n",
      "   Fold 1 accuracy: 76.00 %\n",
      "   Fold 2 accuracy: 78.00 %\n",
      "   Fold 3 accuracy: 74.00 %\n",
      "   Fold 4 accuracy: 74.00 %\n",
      "   Fold 5 accuracy: 78.00 %\n",
      "   Fold 6 accuracy: 74.00 %\n",
      "   Fold 7 accuracy: 80.00 %\n",
      "   Fold 8 accuracy: 68.00 %\n",
      "   Fold 9 accuracy: 72.00 %\n",
      "   Fold 10 accuracy: 77.00 %\n",
      "     Overall test accuracy: 75.10 %\n",
      "     Overall training accuracy: 77.40 %\n",
      "model 3: SVM RBF Gamma=1.000 C=6.00\n",
      "   Fold 1 accuracy: 80.00 %\n",
      "   Fold 2 accuracy: 75.00 %\n",
      "   Fold 3 accuracy: 75.00 %\n",
      "   Fold 4 accuracy: 67.00 %\n",
      "   Fold 5 accuracy: 68.00 %\n",
      "   Fold 6 accuracy: 81.00 %\n",
      "   Fold 7 accuracy: 81.00 %\n",
      "   Fold 8 accuracy: 70.00 %\n",
      "   Fold 9 accuracy: 78.00 %\n",
      "   Fold 10 accuracy: 78.00 %\n",
      "     Overall test accuracy: 75.30 %\n",
      "     Overall training accuracy: 78.40 %\n",
      "model 4: SVM RBF Gamma=1.000 C=8.00\n",
      "   Fold 1 accuracy: 73.00 %\n",
      "   Fold 2 accuracy: 77.00 %\n",
      "   Fold 3 accuracy: 75.00 %\n",
      "   Fold 4 accuracy: 70.00 %\n",
      "   Fold 5 accuracy: 73.00 %\n",
      "   Fold 6 accuracy: 82.00 %\n",
      "   Fold 7 accuracy: 75.00 %\n",
      "   Fold 8 accuracy: 79.00 %\n",
      "   Fold 9 accuracy: 80.00 %\n",
      "   Fold 10 accuracy: 73.00 %\n",
      "     Overall test accuracy: 75.70 %\n",
      "     Overall training accuracy: 79.10 %\n",
      "model 5: SVM RBF Gamma=1.000 C=10.00\n",
      "   Fold 1 accuracy: 68.00 %\n",
      "   Fold 2 accuracy: 74.00 %\n",
      "   Fold 3 accuracy: 81.00 %\n",
      "   Fold 4 accuracy: 72.00 %\n",
      "   Fold 5 accuracy: 76.00 %\n",
      "   Fold 6 accuracy: 83.00 %\n",
      "   Fold 7 accuracy: 74.00 %\n",
      "   Fold 8 accuracy: 74.00 %\n",
      "   Fold 9 accuracy: 78.00 %\n",
      "   Fold 10 accuracy: 71.00 %\n",
      "     Overall test accuracy: 75.10 %\n",
      "     Overall training accuracy: 79.80 %\n",
      "model 6: SVM RBF Gamma=2.000 C=1.00\n",
      "   Fold 1 accuracy: 72.00 %\n",
      "   Fold 2 accuracy: 75.00 %\n",
      "   Fold 3 accuracy: 67.00 %\n",
      "   Fold 4 accuracy: 76.00 %\n",
      "   Fold 5 accuracy: 70.00 %\n",
      "   Fold 6 accuracy: 83.00 %\n",
      "   Fold 7 accuracy: 65.00 %\n",
      "   Fold 8 accuracy: 77.00 %\n",
      "   Fold 9 accuracy: 78.00 %\n",
      "   Fold 10 accuracy: 76.00 %\n",
      "     Overall test accuracy: 73.90 %\n",
      "     Overall training accuracy: 75.70 %\n",
      "model 7: SVM RBF Gamma=2.000 C=2.00\n",
      "   Fold 1 accuracy: 72.00 %\n",
      "   Fold 2 accuracy: 68.00 %\n",
      "   Fold 3 accuracy: 71.00 %\n",
      "   Fold 4 accuracy: 80.00 %\n",
      "   Fold 5 accuracy: 77.00 %\n",
      "   Fold 6 accuracy: 67.00 %\n",
      "   Fold 7 accuracy: 74.00 %\n",
      "   Fold 8 accuracy: 80.00 %\n",
      "   Fold 9 accuracy: 76.00 %\n",
      "   Fold 10 accuracy: 78.00 %\n",
      "     Overall test accuracy: 74.30 %\n",
      "     Overall training accuracy: 77.20 %\n",
      "model 8: SVM RBF Gamma=2.000 C=4.00\n",
      "   Fold 1 accuracy: 79.00 %\n",
      "   Fold 2 accuracy: 74.00 %\n",
      "   Fold 3 accuracy: 83.00 %\n",
      "   Fold 4 accuracy: 64.00 %\n",
      "   Fold 5 accuracy: 79.00 %\n",
      "   Fold 6 accuracy: 77.00 %\n",
      "   Fold 7 accuracy: 75.00 %\n",
      "   Fold 8 accuracy: 83.00 %\n",
      "   Fold 9 accuracy: 78.00 %\n",
      "   Fold 10 accuracy: 64.00 %\n",
      "     Overall test accuracy: 75.60 %\n",
      "     Overall training accuracy: 79.40 %\n",
      "model 9: SVM RBF Gamma=2.000 C=6.00\n",
      "   Fold 1 accuracy: 73.00 %\n",
      "   Fold 2 accuracy: 84.00 %\n",
      "   Fold 3 accuracy: 81.00 %\n",
      "   Fold 4 accuracy: 76.00 %\n",
      "   Fold 5 accuracy: 75.00 %\n",
      "   Fold 6 accuracy: 76.00 %\n",
      "   Fold 7 accuracy: 72.00 %\n",
      "   Fold 8 accuracy: 78.00 %\n",
      "   Fold 9 accuracy: 68.00 %\n",
      "   Fold 10 accuracy: 79.00 %\n",
      "     Overall test accuracy: 76.20 %\n",
      "     Overall training accuracy: 80.50 %\n",
      "model 10: SVM RBF Gamma=2.000 C=8.00\n",
      "   Fold 1 accuracy: 72.00 %\n",
      "   Fold 2 accuracy: 74.00 %\n",
      "   Fold 3 accuracy: 79.00 %\n",
      "   Fold 4 accuracy: 73.00 %\n",
      "   Fold 5 accuracy: 71.00 %\n",
      "   Fold 6 accuracy: 76.00 %\n",
      "   Fold 7 accuracy: 77.00 %\n",
      "   Fold 8 accuracy: 74.00 %\n",
      "   Fold 9 accuracy: 74.00 %\n",
      "   Fold 10 accuracy: 82.00 %\n",
      "     Overall test accuracy: 75.20 %\n",
      "     Overall training accuracy: 81.00 %\n",
      "model 11: SVM RBF Gamma=2.000 C=10.00\n",
      "   Fold 1 accuracy: 78.00 %\n",
      "   Fold 2 accuracy: 76.00 %\n",
      "   Fold 3 accuracy: 77.00 %\n",
      "   Fold 4 accuracy: 84.00 %\n",
      "   Fold 5 accuracy: 80.00 %\n",
      "   Fold 6 accuracy: 78.00 %\n",
      "   Fold 7 accuracy: 77.00 %\n",
      "   Fold 8 accuracy: 73.00 %\n",
      "   Fold 9 accuracy: 69.00 %\n",
      "   Fold 10 accuracy: 73.00 %\n",
      "     Overall test accuracy: 76.50 %\n",
      "     Overall training accuracy: 81.60 %\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# SVM\n",
    "model = 0\n",
    "cont = []\n",
    "results = pd.DataFrame(columns=('name', 'accuracy'))\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "C = [1,2,4,6,8,10]\n",
    "gamma = [1,2]  \n",
    "for g in range(len(gamma)):\n",
    "    acc = []\n",
    "    name = \"SVM RBF Gamma=%.3f\" % (gamma[g])     \n",
    "    for c in range(len(C)):\n",
    "        fold = 1\n",
    "        truth = []\n",
    "        svm_prediction = []\n",
    "        print(\"model %d: SVM RBF Gamma=%.3f C=%.2f\" % (model, gamma[g], C[c]))        \n",
    "        test_count = 0\n",
    "        svm = SVC(C=C[c], kernel='rbf', gamma=gamma[g])\n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            trainX = X[train_idx]\n",
    "            trainY = Y[train_idx]\n",
    "            testX = X[test_idx]\n",
    "            testY = Y[test_idx]\n",
    "            truth.append(testY)\n",
    "            svm.fit(trainX, trainY)\n",
    "            Y_hat = svm.predict(testX)\n",
    "            svm_prediction.append(Y_hat)\n",
    "            print(\"   Fold %d accuracy: %.2f %%\" % (fold, ((np.sum(Y_hat == testY)/len(testY)) * 100.0)))                        \n",
    "            fold += 1\n",
    "        truth = np.concatenate(truth, axis=0)    \n",
    "        svm_prediction = np.concatenate(svm_prediction, axis=0)\n",
    "        test_results = np.sum(svm_prediction == truth)/len(truth)\n",
    "        print(\"     Overall test accuracy: %.2f %%\" % (test_results * 100))  \n",
    "        svm = svm.fit(X, Y)\n",
    "        Y_hat = svm.predict(X)\n",
    "        train_results = np.sum(Y_hat == Y)/len(Y)\n",
    "        print(\"     Overall training accuracy: %.2f %%\" % (train_results * 100.0))  \n",
    "        acc.append([train_results, test_results])   \n",
    "        cont.append([truth, svm_prediction])\n",
    "        model += 1\n",
    "    results = results.append({'name': name, 'accuracy' : acc}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n",
      "vm  0.48135593220338985\n",
      "vn  0.7559322033898305\n",
      "nlp\n",
      "precision:  0.8316831683168316\n",
      "recall:  0.60431654676259\n",
      "F1:  0.7\n",
      "nlp0\n",
      "precision:  0.7164948453608248\n",
      "recall:  0.8910256410256411\n",
      "F1:  0.7\n",
      "ave\n",
      "precision:  0.7740890068388282\n",
      "recall:  0.7476710938941156\n",
      "F1:  0.7\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C=10, kernel='rbf', gamma=2) #79.2%\n",
    "#svm = SVC(C=2, kernel='rbf', gamma=128) #79.6\n",
    "#svm = SVC(C=2, kernel='rbf', gamma=128) \n",
    "train_num = 1\n",
    "for i in range(train_num):\n",
    "    svm.fit(X, Y)\n",
    "    Y2_hat = svm.predict(X2)\n",
    "    vm = np.sum(Y2_hat == Ym2)/len(Ym2)\n",
    "    vn = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "    print(np.sum(Y2_hat))\n",
    "    print(\"vm \", vm)\n",
    "    print(\"vn \",vn)\n",
    "    \n",
    "precision = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2)-np.sum(Y2))\n",
    "f10 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp0\")\n",
    "print(\"precision: \", precision0)\n",
    "print(\"recall: \", recall0)\n",
    "print(\"F1: \", f10)\n",
    "\n",
    "print(\"ave\")\n",
    "print(\"precision: \", (precision+precision0)/2)\n",
    "print(\"recall: \", (recall+recall0)/2)\n",
    "print(\"F1: \", (f1+f10)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Best Model: 11\n",
      "\n",
      "SVM\n",
      "         no  social  Total\n",
      "no      463     164    627\n",
      "social   71     302    373\n",
      "Total   534     466   1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "model = input(\"Enter Best Model: \")\n",
    "best = cont[int(model)]\n",
    "rf_ct = pd.crosstab(best[1], best[0], margins=True)\n",
    "rf_ct.columns = [\"no\", \"social\", \"Total\"]\n",
    "rf_ct.index = [\"no\", \"social\", \"Total\"]\n",
    "print()\n",
    "print(\"SVM\")\n",
    "print(rf_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Sensitivity: 0.64807 Specificity: 0.86704 PPV: 0.80965 NPV: 0.73844 Accuracy: 0.76500\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "Sens = rf_ct.iloc[1][1]/rf_ct.iloc[2][1]\n",
    "Spec = rf_ct.iloc[0][0]/rf_ct.iloc[2][0]\n",
    "PPV = rf_ct.iloc[1][1]/rf_ct.iloc[1][2]\n",
    "NPV = rf_ct.iloc[0][0]/rf_ct.iloc[0][2]\n",
    "ACC = (rf_ct.iloc[0][0] + rf_ct.iloc[1][1]) / rf_ct.iloc[2][2]\n",
    "print(\"Random Forest: Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[463  71]\n",
      " [164 302]]\n",
      "0.7199046483909415\n",
      "0.648068669527897\n",
      "0.8096514745308311\n",
      "0.765\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.87      0.80       534\n",
      "          1       0.81      0.65      0.72       466\n",
      "\n",
      "avg / total       0.77      0.77      0.76      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,classification_report\n",
    "y_true =cont[int(model)][0]\n",
    "y_pred = cont[int(model)][1]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred) )\n",
    "\n",
    "print(recall_score(y_true, y_pred),   )\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  0 : Random Forest trees = 5\n",
      "   Fold 1 accuracy: 67.00 %\n",
      "   Fold 2 accuracy: 67.00 %\n",
      "   Fold 3 accuracy: 76.00 %\n",
      "   Fold 4 accuracy: 69.00 %\n",
      "   Fold 5 accuracy: 65.00 %\n",
      "   Fold 6 accuracy: 67.00 %\n",
      "   Fold 7 accuracy: 63.00 %\n",
      "   Fold 8 accuracy: 65.00 %\n",
      "   Fold 9 accuracy: 80.00 %\n",
      "   Fold 10 accuracy: 69.00 %\n",
      "     Overall test accuracy: 68.80 %\n",
      "     Overall training accuracy: 96.70 %\n",
      "model  1 : Random Forest trees = 10\n",
      "   Fold 1 accuracy: 78.00 %\n",
      "   Fold 2 accuracy: 67.00 %\n",
      "   Fold 3 accuracy: 74.00 %\n",
      "   Fold 4 accuracy: 73.00 %\n",
      "   Fold 5 accuracy: 80.00 %\n",
      "   Fold 6 accuracy: 77.00 %\n",
      "   Fold 7 accuracy: 73.00 %\n",
      "   Fold 8 accuracy: 67.00 %\n",
      "   Fold 9 accuracy: 71.00 %\n",
      "   Fold 10 accuracy: 69.00 %\n",
      "     Overall test accuracy: 72.90 %\n",
      "     Overall training accuracy: 98.70 %\n",
      "model  2 : Random Forest trees = 50\n",
      "   Fold 1 accuracy: 78.00 %\n",
      "   Fold 2 accuracy: 74.00 %\n",
      "   Fold 3 accuracy: 75.00 %\n",
      "   Fold 4 accuracy: 77.00 %\n",
      "   Fold 5 accuracy: 75.00 %\n",
      "   Fold 6 accuracy: 75.00 %\n",
      "   Fold 7 accuracy: 69.00 %\n",
      "   Fold 8 accuracy: 74.00 %\n",
      "   Fold 9 accuracy: 80.00 %\n",
      "   Fold 10 accuracy: 77.00 %\n",
      "     Overall test accuracy: 75.40 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  3 : Random Forest trees = 100\n",
      "   Fold 1 accuracy: 72.00 %\n",
      "   Fold 2 accuracy: 78.00 %\n",
      "   Fold 3 accuracy: 77.00 %\n",
      "   Fold 4 accuracy: 81.00 %\n",
      "   Fold 5 accuracy: 74.00 %\n",
      "   Fold 6 accuracy: 71.00 %\n",
      "   Fold 7 accuracy: 72.00 %\n",
      "   Fold 8 accuracy: 75.00 %\n",
      "   Fold 9 accuracy: 83.00 %\n",
      "   Fold 10 accuracy: 76.00 %\n",
      "     Overall test accuracy: 75.90 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  4 : Random Forest trees = 200\n",
      "   Fold 1 accuracy: 76.00 %\n",
      "   Fold 2 accuracy: 72.00 %\n",
      "   Fold 3 accuracy: 76.00 %\n",
      "   Fold 4 accuracy: 79.00 %\n",
      "   Fold 5 accuracy: 76.00 %\n",
      "   Fold 6 accuracy: 80.00 %\n",
      "   Fold 7 accuracy: 75.00 %\n",
      "   Fold 8 accuracy: 73.00 %\n",
      "   Fold 9 accuracy: 77.00 %\n",
      "   Fold 10 accuracy: 78.00 %\n",
      "     Overall test accuracy: 76.20 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  5 : Random Forest trees = 300\n",
      "   Fold 1 accuracy: 79.00 %\n",
      "   Fold 2 accuracy: 80.00 %\n",
      "   Fold 3 accuracy: 74.00 %\n",
      "   Fold 4 accuracy: 74.00 %\n",
      "   Fold 5 accuracy: 75.00 %\n",
      "   Fold 6 accuracy: 79.00 %\n",
      "   Fold 7 accuracy: 75.00 %\n",
      "   Fold 8 accuracy: 73.00 %\n",
      "   Fold 9 accuracy: 77.00 %\n",
      "   Fold 10 accuracy: 72.00 %\n",
      "     Overall test accuracy: 75.80 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  6 : Random Forest trees = 400\n",
      "   Fold 1 accuracy: 79.00 %\n",
      "   Fold 2 accuracy: 74.00 %\n",
      "   Fold 3 accuracy: 82.00 %\n",
      "   Fold 4 accuracy: 81.00 %\n",
      "   Fold 5 accuracy: 75.00 %\n",
      "   Fold 6 accuracy: 70.00 %\n",
      "   Fold 7 accuracy: 77.00 %\n",
      "   Fold 8 accuracy: 66.00 %\n",
      "   Fold 9 accuracy: 79.00 %\n",
      "   Fold 10 accuracy: 82.00 %\n",
      "     Overall test accuracy: 76.50 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  7 : Random Forest trees = 500\n",
      "   Fold 1 accuracy: 77.00 %\n",
      "   Fold 2 accuracy: 71.00 %\n",
      "   Fold 3 accuracy: 87.00 %\n",
      "   Fold 4 accuracy: 73.00 %\n",
      "   Fold 5 accuracy: 72.00 %\n",
      "   Fold 6 accuracy: 76.00 %\n",
      "   Fold 7 accuracy: 84.00 %\n",
      "   Fold 8 accuracy: 79.00 %\n",
      "   Fold 9 accuracy: 70.00 %\n",
      "   Fold 10 accuracy: 76.00 %\n",
      "     Overall test accuracy: 76.50 %\n",
      "     Overall training accuracy: 100.00 %\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# RandomForest\n",
    "model=0\n",
    "results = []\n",
    "cont = []\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "trees = [5, 10, 50, 100, 200, 300, 400, 500]\n",
    "for t in range(len(trees)):\n",
    "    fold = 1\n",
    "    truth = []\n",
    "    rf_prediction = []\n",
    "    print(\"model \", t, \": Random Forest trees = \" + str(trees[t]))\n",
    "    test_count = 0\n",
    "    rf = RandomForestClassifier(n_estimators=trees[t], criterion='entropy', n_jobs=-1, )\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        trainX = X[train_idx]\n",
    "        trainY = Y[train_idx]\n",
    "        testX = X[test_idx]\n",
    "        testY = Y[test_idx]\n",
    "        truth.append(testY)\n",
    "        rf.fit(trainX, trainY)\n",
    "        Y_hat = rf.predict(testX)\n",
    "        rf_prediction.append(Y_hat)\n",
    "        print(\"   Fold %d accuracy: %.2f %%\" % (fold, ((np.sum(Y_hat == testY)/len(testY)) * 100.0)))                        \n",
    "        fold += 1\n",
    "    truth = np.concatenate(truth, axis=0)    \n",
    "    rf_prediction = np.concatenate(rf_prediction, axis=0)\n",
    "    test_results = np.sum(rf_prediction == truth)/len(truth)\n",
    "    print(\"     Overall test accuracy: %.2f %%\" % (test_results * 100))  \n",
    "    rf = rf.fit(X, Y)\n",
    "    Y_hat = rf.predict(X)\n",
    "    train_results = np.sum(Y_hat == Y)/len(Y)\n",
    "    print(\"     Overall training accuracy: %.2f %%\" % (train_results * 100.0))  \n",
    "    results.append([train_results, test_results])   \n",
    "    cont.append([truth, rf_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364\n",
      "vm  0.5050847457627119\n",
      "vn  0.7389830508474576\n",
      "nlp\n",
      "precision:  0.7554945054945055\n",
      "recall:  0.6594724220623501\n",
      "F1:  0.7042253521126761\n",
      "nlp0\n",
      "precision:  0.727447216890595\n",
      "recall:  0.8098290598290598\n",
      "F1:  0.7042253521126761\n",
      "ave\n",
      "precision:  0.7414708611925502\n",
      "recall:  0.734650740945705\n",
      "F1:  0.7042253521126761\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=400, criterion='entropy', n_jobs=-1, )\n",
    "train_num = 1\n",
    "for i in range(train_num):\n",
    "    rf.fit(X, Y)\n",
    "    Y2_hat = rf.predict(X2)\n",
    "    vm = np.sum(Y2_hat == Ym2)/len(Ym2)\n",
    "    vn = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "    print(np.sum(Y2_hat))\n",
    "    print(\"vm \", vm)\n",
    "    print(\"vn \",vn)\n",
    "    \n",
    "precision = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2)-np.sum(Y2))\n",
    "f10 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp0\")\n",
    "print(\"precision: \", precision0)\n",
    "print(\"recall: \", recall0)\n",
    "print(\"F1: \", f10)\n",
    "\n",
    "print(\"ave\")\n",
    "print(\"precision: \", (precision+precision0)/2)\n",
    "print(\"recall: \", (recall+recall0)/2)\n",
    "print(\"F1: \", (f1+f10)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Best Model: 6\n",
      "\n",
      "Random Forest\n",
      "         no  social  Total\n",
      "no      453     154    607\n",
      "social   81     312    393\n",
      "Total   534     466   1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "model = input(\"Enter Best Model: \")\n",
    "best = cont[int(model)]\n",
    "rf_ct = pd.crosstab(best[1], best[0], margins=True)\n",
    "rf_ct.columns = [\"no\", \"social\", \"Total\"]\n",
    "rf_ct.index = [\"no\", \"social\", \"Total\"]\n",
    "print()\n",
    "print(\"Random Forest\")\n",
    "print(rf_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Sensitivity: 0.66953 Specificity: 0.84831 PPV: 0.79389 NPV: 0.74629 Accuracy: 0.76500\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "Sens = rf_ct.iloc[1][1]/rf_ct.iloc[2][1]\n",
    "Spec = rf_ct.iloc[0][0]/rf_ct.iloc[2][0]\n",
    "PPV = rf_ct.iloc[1][1]/rf_ct.iloc[1][2]\n",
    "NPV = rf_ct.iloc[0][0]/rf_ct.iloc[0][2]\n",
    "ACC = (rf_ct.iloc[0][0] + rf_ct.iloc[1][1]) / rf_ct.iloc[2][2]\n",
    "print(\"Random Forest: Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[453  81]\n",
      " [154 312]]\n",
      "0.7264260768335274\n",
      "0.6695278969957081\n",
      "0.7938931297709924\n",
      "0.765\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.85      0.79       534\n",
      "          1       0.79      0.67      0.73       466\n",
      "\n",
      "avg / total       0.77      0.77      0.76      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,classification_report\n",
    "y_true =cont[int(model)][0]\n",
    "y_pred = cont[int(model)][1]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred) )\n",
    "\n",
    "\n",
    "\n",
    "print(recall_score(y_true, y_pred),   )\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.950000\n",
      "Test set score: 0.720000\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.utils import shuffle\n",
    "X, Y = shuffle(X, Y)\n",
    "split = int(len(Y) * 4/5)\n",
    "trainX = X[:split, :]\n",
    "trainY = Y[:split]\n",
    "testX = X[split:, :]\n",
    "testY = Y[split:]\n",
    "\n",
    "#%%\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, alpha=1e-4,\n",
    "                    solver='adam', verbose=False, tol=1e-4, random_state=1)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4,\n",
    "#                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "#                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(trainX, trainY)\n",
    "print(\"Training set score: %f\" % mlp.score(trainX, trainY))\n",
    "print(\"Test set score: %f\" % mlp.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\n",
      "vm  0.5005649717514125\n",
      "vn  0.7502824858757062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, Y = shuffle(X, Y)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,),max_iter=500, alpha=1e-4)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(100,),max_iter=1000, alpha=1e-4) 67.5%\n",
    "mlp.fit(X,Y)\n",
    "\n",
    "Y2_hat = mlp.predict(X2)\n",
    "vm = np.sum(Y2_hat == Ym2)/len(Ym2)\n",
    "vn = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "print(np.sum(Y2_hat))\n",
    "print(\"vm \", vm)\n",
    "print(\"vn \",vn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\n",
      "vm  0.5073446327683616\n",
      "vn  0.7548022598870057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, Y = shuffle(X, Y)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(300,),max_iter=500, alpha=1e-4)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(100,),max_iter=1000, alpha=1e-4) 67.5%\n",
    "mlp.fit(X,Y)\n",
    "\n",
    "Y2_hat = mlp.predict(X2)\n",
    "vm = np.sum(Y2_hat == Ym2)/len(Ym2)\n",
    "vn = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "print(np.sum(Y2_hat))\n",
    "print(\"vm \", vm)\n",
    "print(\"vn \",vn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
