{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIMH Project - Machine Learning - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import math\n",
    "import chardet\n",
    "os.chdir('Z:/project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pat_visit</th>\n",
       "      <th>m1</th>\n",
       "      <th>n1</th>\n",
       "      <th>txt1</th>\n",
       "      <th>fsize</th>\n",
       "      <th>m1_1</th>\n",
       "      <th>n1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2194751_1850486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MENTAL STATUS EXAM:  Mr. Taylor is slightly di...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11315199_2148732</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MRN:                     11315199\\r\\n...... MR...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11173259_2375848</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MRN:                     11173259\\r\\n...... Me...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11145190_1885052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MRN:                     11145190\\r\\n...... MR...</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6198790_1907260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mental Status Exam:\\r\\nAppearance: Dressed cas...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         pat_visit  m1  n1  \\\n",
       "0           0   2194751_1850486   0   0   \n",
       "1           1  11315199_2148732   0   0   \n",
       "2           2  11173259_2375848   0   0   \n",
       "3           3  11145190_1885052   0   0   \n",
       "4           4   6198790_1907260   0   0   \n",
       "\n",
       "                                                txt1  fsize  m1_1  n1_1  \n",
       "0  MENTAL STATUS EXAM:  Mr. Taylor is slightly di...     17     0     0  \n",
       "1  MRN:                     11315199\\r\\n...... MR...     10     0     0  \n",
       "2  MRN:                     11173259\\r\\n...... Me...     16     0     0  \n",
       "3  MRN:                     11145190\\r\\n...... MR...     14     0     0  \n",
       "4  Mental Status Exam:\\r\\nAppearance: Dressed cas...     20     0     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "#data = pd.read_csv(\"./results/pat_visit_score_match_1127.csv\")\n",
    "data = pd.read_csv(\"./results/train_2925.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2925, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pat_visit</th>\n",
       "      <th>m1</th>\n",
       "      <th>n1</th>\n",
       "      <th>txt1</th>\n",
       "      <th>fsize</th>\n",
       "      <th>m1_1</th>\n",
       "      <th>n1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>766</td>\n",
       "      <td>14221485_2180859</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MRN:                     14221485\\r\\n...... Me...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>1536</td>\n",
       "      <td>12585717_190743768</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>MRN: 12585717\\r\\n...... MRN: 12585717\\r\\n........</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1459</td>\n",
       "      <td>17063058_2422970</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>MRN:                     17063058\\r\\n...... Me...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>6311286_1941616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MRN:                     6311286\\r\\n...... MRN...</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>1347</td>\n",
       "      <td>20463231_189138737</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>MRN: 20463231\\r\\n...... MRN: 20463231\\r\\n........</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0           pat_visit  m1  n1  \\\n",
       "766          766    14221485_2180859   0   1   \n",
       "1536        1536  12585717_190743768   0   2   \n",
       "1459        1459    17063058_2422970   0   2   \n",
       "23            23     6311286_1941616   0   0   \n",
       "1347        1347  20463231_189138737   0   1   \n",
       "\n",
       "                                                   txt1  fsize  m1_1  n1_1  \n",
       "766   MRN:                     14221485\\r\\n...... Me...     13     0     0  \n",
       "1536  MRN: 12585717\\r\\n...... MRN: 12585717\\r\\n........     38     0     1  \n",
       "1459  MRN:                     17063058\\r\\n...... Me...     23     0     1  \n",
       "23    MRN:                     6311286\\r\\n...... MRN...     23     0     0  \n",
       "1347  MRN: 20463231\\r\\n...... MRN: 20463231\\r\\n........     43     0     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data = shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelm=data[data.columns[6]].tolist()\n",
    "labeln=data[data.columns[7]].tolist()\n",
    "#labelm2=data[data.columns[11]].tolist()\n",
    "#labeln2=data[data.columns[12]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6218803418803419"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_m1 = np.array(labelm)\n",
    "arr_n1 = np.array(labeln)\n",
    "#arr_m2 = np.array(labelm2)\n",
    "#arr_n2 = np.array(labeln2)\n",
    "sum(arr_m1 == arr_n1)/len(arr_m1)  #, sum(arr_m2 == arr_n2)/len(arr_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "corpusList=data[data.columns[4]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpusList2=data[data.columns[7]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2925"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpusList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(corpusList2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "def tokenize(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = [ token for token in tokens if re.search('(^[a-zA-Z]+$)', token) ]\n",
    "    a=[]\n",
    "    for i in filtered_tokens:\n",
    "        a.append(WordNetLemmatizer().lemmatize(i,'v'))\n",
    "    return a\n",
    "    #return filtered_tokens\n",
    "\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(2925, 2499106)\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "cv = TfidfVectorizer(lowercase=True,\n",
    "                     ngram_range=(1, 4), preprocessor=None, stop_words='english',\n",
    "                     strip_accents=None, tokenizer=tokenize, vocabulary=None)\n",
    "X1 = cv.fit_transform(corpusList)\n",
    "lexicon = cv.get_feature_names()\n",
    "#print (lexicon)\n",
    "print()\n",
    "\n",
    "#%%\n",
    "x=X1  ## for select fetures \n",
    "print(x.shape)\n",
    "\n",
    "pkl.dump( x, open( \"./results/tfidf_2925.pickle\", \"wb\" ) )\n",
    "pkl.dump( lexicon, open( \"./results/lexicon_2925.pickle\", \"wb\" ) )\n",
    "#x1 = pkl.load( open( \"./results/tfidf_4801395.pickle\", \"rb\" ) )\n",
    "#lexicon1 = pkl.load( open( \"./results/lexicon_4801395.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2925, 2499106)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\"\"\"cv2 = TfidfVectorizer(lowercase=True,\n",
    "                     ngram_range=(1, 4), preprocessor=None, stop_words='english',\n",
    "                     strip_accents=None, tokenizer=tokenize, vocabulary=None)\n",
    "X2 = cv2.fit_transform(corpusList2)\n",
    "lexicon2 = cv2.get_feature_names()\n",
    "#print (lexicon)\n",
    "print()\n",
    "\n",
    "#%%\n",
    "x2=X2  ## for select fetures \n",
    "print(x2.shape)\n",
    "\n",
    "pkl.dump( x2, open( \"./results/tfidf_1885_2.pickle\", \"wb\" ) )\n",
    "pkl.dump( lexicon2, open( \"./results/lexicon_1885_2.pickle\", \"wb\" ) )\n",
    "#x1 = pkl.load( open( \"./results/tfidf_4801395.pickle\", \"rb\" ) )\n",
    "#lexicon1 = pkl.load( open( \"./results/lexicon_4801395.pickle\", \"rb\" ) )\"\"\"\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ym = np.array(labelm)\n",
    "Yn = np.array(labeln)\n",
    "#Ym2 = np.array(labelm2)\n",
    "#Yn2 = np.array(labeln2)\n",
    "pkl.dump( Ym, open( \"./results/ym_2925.pickle\", \"wb\" ) )\n",
    "pkl.dump( Yn, open( \"./results/yn_2925.pickle\", \"wb\" ) )\n",
    "#pkl.dump( Ym2, open( \"./results/ym_1885_2.pickle\", \"wb\" ) )\n",
    "#pkl.dump( Yn2, open( \"./results/yn_1885_2.pickle\", \"wb\" ) )\n",
    "#print(Y)  ## class level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#%%\n",
    "#test\n",
    "cvt = TfidfVectorizer(lowercase=True,\n",
    "                     ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
    "                     strip_accents=None, tokenizer=tokenize, vocabulary=None)\n",
    "\n",
    "X1t = cvt.fit_transform(corpusList_test)\n",
    "print(X1t.shape)\n",
    "print()\n",
    "lexicon_test = cvt.get_feature_names()\n",
    "#print (lexicon)\n",
    "print()\n",
    "\n",
    "#%%\n",
    "xt=X1t  ## for select fetures \n",
    "print(xt.shape)\n",
    "\n",
    "Ym = np.array(labels_testm)\n",
    "Yn = np.array(labels_testn)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0] [0 0 0 0 0 0 0 1 0 0] [1 1 0 ... 0 0 1]\n",
      "[0 1 1 0 0 0 0 1 0 0] [0 0 0 0 0 0 1 1 0 0] [1 1 0 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(Ym[0:10], Ym[480:490], Ym[1865:])  ## class level\n",
    "print(Yn[0:10], Yn[480:490], Yn[1865:])  ## class level\n",
    "#print(Ym2[0:10], Ym2[480:490], Ym2[1865:])  ## class level\n",
    "#print(Yn2[0:10], Yn2[480:490], Yn2[1865:])  ## class level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2925, 800)\n"
     ]
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=800).fit_transform(x, Yn)   # select 800 features\n",
    "\n",
    "#%%\n",
    "X=X_new        # make unque name for next cell \n",
    "print(X.shape)\n",
    "#Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl.dump( X, open( \"./results/tfidf_2925_800.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pkl.load( open( \"./results/tfidf_2925.pickle\", \"rb\" ) )\n",
    "Yn = pkl.load( open( \"./results/yn_2925.pickle\", \"rb\" ) )\n",
    "\n",
    "X_new2 = SelectKBest(chi2, k=1200).fit_transform(x, Yn)\n",
    "pkl.dump( X_new2, open( \"./results/tfidf_2925_1200.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pkl.load( open( \"./results/tfidf_2925_1200.pickle\", \"rb\" ) )\n",
    "Ym = pkl.load( open( \"./results/ym_2925.pickle\", \"rb\" ) )\n",
    "Yn = pkl.load( open( \"./results/yn_2925.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_new[:1900]\n",
    "X2 = X_new[1900:]\n",
    "Y = Yn[:1900]\n",
    "Y2 = Yn[1900:]\n",
    "Ym1 = Ym[:1900]\n",
    "Ym2 = Ym[1900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1395, 600)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"X2_new = SelectKBest(chi2, k=600).fit_transform(xt, Ym)   # select 600 features\n",
    "X2_new.shape\n",
    "\n",
    "#%%\n",
    "X2=X2_new        # make unque name for next cell \n",
    "X2_new.shape\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  0 : ExtraTreesClassifier = 10\n",
      "   Fold 1 accuracy: 83.68 %\n",
      "   Fold 2 accuracy: 78.95 %\n",
      "   Fold 3 accuracy: 78.95 %\n",
      "   Fold 4 accuracy: 76.84 %\n",
      "   Fold 5 accuracy: 80.00 %\n",
      "   Fold 6 accuracy: 82.11 %\n",
      "   Fold 7 accuracy: 69.47 %\n",
      "   Fold 8 accuracy: 73.16 %\n",
      "   Fold 9 accuracy: 76.32 %\n",
      "   Fold 10 accuracy: 76.84 %\n",
      "     Overall test accuracy: 77.63 %\n",
      "     Overall training accuracy: 99.74 %\n",
      "model  1 : ExtraTreesClassifier = 30\n",
      "   Fold 1 accuracy: 78.42 %\n",
      "   Fold 2 accuracy: 77.89 %\n",
      "   Fold 3 accuracy: 76.32 %\n",
      "   Fold 4 accuracy: 81.58 %\n",
      "   Fold 5 accuracy: 75.26 %\n",
      "   Fold 6 accuracy: 76.32 %\n",
      "   Fold 7 accuracy: 79.47 %\n",
      "   Fold 8 accuracy: 80.00 %\n",
      "   Fold 9 accuracy: 77.37 %\n",
      "   Fold 10 accuracy: 72.63 %\n",
      "     Overall test accuracy: 77.53 %\n",
      "     Overall training accuracy: 99.89 %\n",
      "model  2 : ExtraTreesClassifier = 60\n",
      "   Fold 1 accuracy: 78.95 %\n",
      "   Fold 2 accuracy: 77.89 %\n",
      "   Fold 3 accuracy: 78.95 %\n",
      "   Fold 4 accuracy: 78.42 %\n",
      "   Fold 5 accuracy: 80.00 %\n",
      "   Fold 6 accuracy: 82.63 %\n",
      "   Fold 7 accuracy: 79.47 %\n",
      "   Fold 8 accuracy: 80.00 %\n",
      "   Fold 9 accuracy: 78.42 %\n",
      "   Fold 10 accuracy: 76.84 %\n",
      "     Overall test accuracy: 79.16 %\n",
      "     Overall training accuracy: 99.95 %\n",
      "model  3 : ExtraTreesClassifier = 100\n",
      "   Fold 1 accuracy: 82.11 %\n",
      "   Fold 2 accuracy: 76.84 %\n",
      "   Fold 3 accuracy: 84.74 %\n",
      "   Fold 4 accuracy: 76.32 %\n",
      "   Fold 5 accuracy: 76.84 %\n",
      "   Fold 6 accuracy: 77.37 %\n",
      "   Fold 7 accuracy: 78.42 %\n",
      "   Fold 8 accuracy: 78.95 %\n",
      "   Fold 9 accuracy: 74.74 %\n",
      "   Fold 10 accuracy: 82.11 %\n",
      "     Overall test accuracy: 78.84 %\n",
      "     Overall training accuracy: 99.89 %\n",
      "model  4 : ExtraTreesClassifier = 300\n",
      "   Fold 1 accuracy: 78.95 %\n",
      "   Fold 2 accuracy: 72.63 %\n",
      "   Fold 3 accuracy: 78.42 %\n",
      "   Fold 4 accuracy: 81.58 %\n",
      "   Fold 5 accuracy: 84.74 %\n",
      "   Fold 6 accuracy: 74.74 %\n",
      "   Fold 7 accuracy: 80.53 %\n",
      "   Fold 8 accuracy: 75.26 %\n",
      "   Fold 9 accuracy: 80.53 %\n",
      "   Fold 10 accuracy: 81.05 %\n",
      "     Overall test accuracy: 78.84 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  5 : ExtraTreesClassifier = 500\n",
      "   Fold 1 accuracy: 76.84 %\n",
      "   Fold 2 accuracy: 81.05 %\n",
      "   Fold 3 accuracy: 80.00 %\n",
      "   Fold 4 accuracy: 81.05 %\n",
      "   Fold 5 accuracy: 76.84 %\n",
      "   Fold 6 accuracy: 83.68 %\n",
      "   Fold 7 accuracy: 75.26 %\n",
      "   Fold 8 accuracy: 79.47 %\n",
      "   Fold 9 accuracy: 76.32 %\n",
      "   Fold 10 accuracy: 75.79 %\n",
      "     Overall test accuracy: 78.63 %\n",
      "     Overall training accuracy: 100.00 %\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# ExtraTreesClassifier\n",
    "model=0\n",
    "results = []\n",
    "cont = []\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "trees = [10, 30, 60, 100, 300, 500]\n",
    "for t in range(len(trees)):\n",
    "    fold = 1\n",
    "    truth = []\n",
    "    rf_prediction = []\n",
    "    print(\"model \", t, \": ExtraTreesClassifier = \" + str(trees[t]))\n",
    "    test_count = 0\n",
    "    rf = ExtraTreesClassifier(bootstrap=False,\n",
    "           criterion='entropy', max_depth=15, max_features=0.9,\n",
    "           max_leaf_nodes=None, min_impurity_decrease=1e-045,\n",
    "           min_samples_leaf=1, min_samples_split=3,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=trees[t], n_jobs=-1,\n",
    "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        trainX = X[train_idx]\n",
    "        trainY = Y[train_idx]\n",
    "        testX = X[test_idx]\n",
    "        testY = Y[test_idx]\n",
    "        truth.append(testY)\n",
    "        rf.fit(trainX, trainY)\n",
    "        Y_hat = rf.predict(testX)\n",
    "        rf_prediction.append(Y_hat)\n",
    "        print(\"   Fold %d accuracy: %.2f %%\" % (fold, ((np.sum(Y_hat == testY)/len(testY)) * 100.0)))                        \n",
    "        fold += 1\n",
    "    truth = np.concatenate(truth, axis=0)    \n",
    "    rf_prediction = np.concatenate(rf_prediction, axis=0)\n",
    "    test_results = np.sum(rf_prediction == truth)/len(truth)\n",
    "    print(\"     Overall test accuracy: %.2f %%\" % (test_results * 100))  \n",
    "    rf = rf.fit(X, Y)\n",
    "    Y_hat = rf.predict(X)\n",
    "    train_results = np.sum(Y_hat == Y)/len(Y)\n",
    "    print(\"     Overall training accuracy: %.2f %%\" % (train_results * 100.0))  \n",
    "    results.append([train_results, test_results])   \n",
    "    cont.append([truth, rf_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ExtraTreesClassifier(bootstrap=False,\n",
    "       criterion='entropy', max_depth=15, max_features=0.9,\n",
    "       max_leaf_nodes=None, min_impurity_decrease=1e-045,\n",
    "       min_samples_leaf=1, min_samples_split=3,\n",
    "       min_weight_fraction_leaf=0.0, n_estimators=60, n_jobs=-1,      #trees[t] = 100\n",
    "       oob_score=False, random_state=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n",
      "vm  0.6409756097560976\n",
      "vn  0.7648780487804878\n",
      "nlp\n",
      "precision:  0.6896551724137931\n",
      "recall:  0.44025157232704404\n",
      "F1:  0.5374280230326296\n",
      "nlp0\n",
      "precision:  0.7834549878345499\n",
      "recall:  0.9108910891089109\n",
      "F1:  0.5374280230326296\n",
      "ave\n",
      "precision:  0.7365550801241716\n",
      "recall:  0.6755713307179775\n",
      "F1:  0.5374280230326296\n"
     ]
    }
   ],
   "source": [
    "train_num = 1\n",
    "for i in range(train_num):\n",
    "    rf.fit(X, Y)\n",
    "    Y2_hat = rf.predict(X2)\n",
    "    vm = np.sum(Y2_hat == Ym2)/len(Ym2)\n",
    "    vn = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "    print(np.sum(Y2_hat))\n",
    "    print(\"vm \", vm)\n",
    "    print(\"vn \",vn)\n",
    "    \n",
    "precision = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2)-np.sum(Y2))\n",
    "f10 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp0\")\n",
    "print(\"precision: \", precision0)\n",
    "print(\"recall: \", recall0)\n",
    "print(\"F1: \", f10)\n",
    "\n",
    "print(\"ave\")\n",
    "print(\"precision: \", (precision+precision0)/2)\n",
    "print(\"recall: \", (recall+recall0)/2)\n",
    "print(\"F1: \", (f1+f10)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(885, 800)\n",
      "885\n"
     ]
    }
   ],
   "source": [
    "print(X2.shape)\n",
    "print(len(Y2_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Best Model: 2\n",
      "\n",
      "ExtraTrees\n",
      "          no  social  Total\n",
      "no      1204     278   1482\n",
      "social   118     300    418\n",
      "Total   1322     578   1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "model = input(\"Enter Best Model: \")\n",
    "best = cont[int(model)]\n",
    "rf_ct = pd.crosstab(best[1], best[0], margins=True)\n",
    "rf_ct.columns = [\"no\", \"social\", \"Total\"]\n",
    "rf_ct.index = [\"no\", \"social\", \"Total\"]\n",
    "print()\n",
    "print(\"ExtraTrees\")\n",
    "print(rf_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1204  118]\n",
      " [ 278  300]]\n",
      "0.6024096385542168\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,classification_report\n",
    "y_true =cont[int(model)][0]\n",
    "y_pred = cont[int(model)][1]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5190311418685121\n",
      "0.7177033492822966\n",
      "0.791578947368421\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.91      0.86      1322\n",
      "          1       0.72      0.52      0.60       578\n",
      "\n",
      "avg / total       0.78      0.79      0.78      1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(y_true, y_pred),   )\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees: Sensitivity: 0.51903 Specificity: 0.91074 PPV: 0.71770 NPV: 0.81242 Accuracy: 0.79158\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "Sens = rf_ct.iloc[1][1]/rf_ct.iloc[2][1]\n",
    "Spec = rf_ct.iloc[0][0]/rf_ct.iloc[2][0]\n",
    "PPV = rf_ct.iloc[1][1]/rf_ct.iloc[1][2]\n",
    "NPV = rf_ct.iloc[0][0]/rf_ct.iloc[0][2]\n",
    "ACC = (rf_ct.iloc[0][0] + rf_ct.iloc[1][1]) / rf_ct.iloc[2][2]\n",
    "print(\"ExtraTrees: Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC =  0.7148862214637568\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(best[0], best[1], pos_label=1)\n",
    "roc_auc = auc(rf_fpr, rf_tpr)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(rf_fpr, rf_tpr, label='ExtraTrees')\n",
    "plt.xlabel('False positive rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(\"AUC = \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0: SVM RBF Gamma=1.000 C=1.00\n",
      "   Fold 1 accuracy: 71.05 %\n",
      "   Fold 2 accuracy: 70.53 %\n",
      "   Fold 3 accuracy: 67.37 %\n",
      "   Fold 4 accuracy: 74.74 %\n",
      "   Fold 5 accuracy: 73.16 %\n",
      "   Fold 6 accuracy: 72.63 %\n",
      "   Fold 7 accuracy: 68.95 %\n",
      "   Fold 8 accuracy: 70.53 %\n",
      "   Fold 9 accuracy: 69.47 %\n",
      "   Fold 10 accuracy: 73.16 %\n",
      "     Overall test accuracy: 71.16 %\n",
      "     Overall training accuracy: 72.89 %\n",
      "model 1: SVM RBF Gamma=1.000 C=2.00\n",
      "   Fold 1 accuracy: 75.79 %\n",
      "   Fold 2 accuracy: 72.63 %\n",
      "   Fold 3 accuracy: 75.26 %\n",
      "   Fold 4 accuracy: 68.95 %\n",
      "   Fold 5 accuracy: 76.84 %\n",
      "   Fold 6 accuracy: 75.26 %\n",
      "   Fold 7 accuracy: 74.74 %\n",
      "   Fold 8 accuracy: 81.05 %\n",
      "   Fold 9 accuracy: 75.26 %\n",
      "   Fold 10 accuracy: 76.32 %\n",
      "     Overall test accuracy: 75.21 %\n",
      "     Overall training accuracy: 77.53 %\n",
      "model 2: SVM RBF Gamma=1.000 C=4.00\n",
      "   Fold 1 accuracy: 73.68 %\n",
      "   Fold 2 accuracy: 81.05 %\n",
      "   Fold 3 accuracy: 80.53 %\n",
      "   Fold 4 accuracy: 71.58 %\n",
      "   Fold 5 accuracy: 76.84 %\n",
      "   Fold 6 accuracy: 74.74 %\n",
      "   Fold 7 accuracy: 80.00 %\n",
      "   Fold 8 accuracy: 79.47 %\n",
      "   Fold 9 accuracy: 82.11 %\n",
      "   Fold 10 accuracy: 82.11 %\n",
      "     Overall test accuracy: 78.21 %\n",
      "     Overall training accuracy: 81.68 %\n",
      "model 3: SVM RBF Gamma=1.000 C=6.00\n",
      "   Fold 1 accuracy: 78.95 %\n",
      "   Fold 2 accuracy: 78.95 %\n",
      "   Fold 3 accuracy: 83.16 %\n",
      "   Fold 4 accuracy: 74.74 %\n",
      "   Fold 5 accuracy: 85.26 %\n",
      "   Fold 6 accuracy: 78.95 %\n",
      "   Fold 7 accuracy: 75.79 %\n",
      "   Fold 8 accuracy: 82.11 %\n",
      "   Fold 9 accuracy: 82.11 %\n",
      "   Fold 10 accuracy: 77.37 %\n",
      "     Overall test accuracy: 79.74 %\n",
      "     Overall training accuracy: 84.16 %\n",
      "model 4: SVM RBF Gamma=1.000 C=8.00\n",
      "   Fold 1 accuracy: 81.05 %\n",
      "   Fold 2 accuracy: 82.11 %\n",
      "   Fold 3 accuracy: 79.47 %\n",
      "   Fold 4 accuracy: 76.32 %\n",
      "   Fold 5 accuracy: 75.79 %\n",
      "   Fold 6 accuracy: 81.58 %\n",
      "   Fold 7 accuracy: 80.00 %\n",
      "   Fold 8 accuracy: 82.11 %\n",
      "   Fold 9 accuracy: 84.21 %\n",
      "   Fold 10 accuracy: 83.16 %\n",
      "     Overall test accuracy: 80.58 %\n",
      "     Overall training accuracy: 85.32 %\n",
      "model 5: SVM RBF Gamma=1.000 C=10.00\n",
      "   Fold 1 accuracy: 82.11 %\n",
      "   Fold 2 accuracy: 78.42 %\n",
      "   Fold 3 accuracy: 80.00 %\n",
      "   Fold 4 accuracy: 80.53 %\n",
      "   Fold 5 accuracy: 79.47 %\n",
      "   Fold 6 accuracy: 83.68 %\n",
      "   Fold 7 accuracy: 80.53 %\n",
      "   Fold 8 accuracy: 82.11 %\n",
      "   Fold 9 accuracy: 80.53 %\n",
      "   Fold 10 accuracy: 83.68 %\n",
      "     Overall test accuracy: 81.11 %\n",
      "     Overall training accuracy: 86.32 %\n",
      "model 6: SVM RBF Gamma=2.000 C=1.00\n",
      "   Fold 1 accuracy: 73.16 %\n",
      "   Fold 2 accuracy: 76.32 %\n",
      "   Fold 3 accuracy: 77.89 %\n",
      "   Fold 4 accuracy: 73.16 %\n",
      "   Fold 5 accuracy: 77.89 %\n",
      "   Fold 6 accuracy: 76.84 %\n",
      "   Fold 7 accuracy: 71.58 %\n",
      "   Fold 8 accuracy: 77.37 %\n",
      "   Fold 9 accuracy: 76.84 %\n",
      "   Fold 10 accuracy: 78.95 %\n",
      "     Overall test accuracy: 76.00 %\n",
      "     Overall training accuracy: 78.58 %\n",
      "model 7: SVM RBF Gamma=2.000 C=2.00\n",
      "   Fold 1 accuracy: 76.84 %\n",
      "   Fold 2 accuracy: 79.47 %\n",
      "   Fold 3 accuracy: 78.42 %\n",
      "   Fold 4 accuracy: 81.05 %\n",
      "   Fold 5 accuracy: 78.42 %\n",
      "   Fold 6 accuracy: 80.00 %\n",
      "   Fold 7 accuracy: 77.89 %\n",
      "   Fold 8 accuracy: 78.42 %\n",
      "   Fold 9 accuracy: 77.37 %\n",
      "   Fold 10 accuracy: 80.00 %\n",
      "     Overall test accuracy: 78.79 %\n",
      "     Overall training accuracy: 81.84 %\n",
      "model 8: SVM RBF Gamma=2.000 C=4.00\n",
      "   Fold 1 accuracy: 82.63 %\n",
      "   Fold 2 accuracy: 78.42 %\n",
      "   Fold 3 accuracy: 84.21 %\n",
      "   Fold 4 accuracy: 78.95 %\n",
      "   Fold 5 accuracy: 78.42 %\n",
      "   Fold 6 accuracy: 79.47 %\n",
      "   Fold 7 accuracy: 82.11 %\n",
      "   Fold 8 accuracy: 83.68 %\n",
      "   Fold 9 accuracy: 83.16 %\n",
      "   Fold 10 accuracy: 79.47 %\n",
      "     Overall test accuracy: 81.05 %\n",
      "     Overall training accuracy: 85.32 %\n",
      "model 9: SVM RBF Gamma=2.000 C=6.00\n",
      "   Fold 1 accuracy: 82.63 %\n",
      "   Fold 2 accuracy: 83.68 %\n",
      "   Fold 3 accuracy: 87.89 %\n",
      "   Fold 4 accuracy: 82.11 %\n",
      "   Fold 5 accuracy: 85.79 %\n",
      "   Fold 6 accuracy: 83.16 %\n",
      "   Fold 7 accuracy: 81.05 %\n",
      "   Fold 8 accuracy: 77.89 %\n",
      "   Fold 9 accuracy: 78.42 %\n",
      "   Fold 10 accuracy: 76.84 %\n",
      "     Overall test accuracy: 81.95 %\n",
      "     Overall training accuracy: 87.37 %\n",
      "model 10: SVM RBF Gamma=2.000 C=8.00\n",
      "   Fold 1 accuracy: 84.74 %\n",
      "   Fold 2 accuracy: 82.11 %\n",
      "   Fold 3 accuracy: 85.79 %\n",
      "   Fold 4 accuracy: 83.68 %\n",
      "   Fold 5 accuracy: 81.05 %\n",
      "   Fold 6 accuracy: 80.00 %\n",
      "   Fold 7 accuracy: 77.37 %\n",
      "   Fold 8 accuracy: 84.74 %\n",
      "   Fold 9 accuracy: 85.79 %\n",
      "   Fold 10 accuracy: 81.58 %\n",
      "     Overall test accuracy: 82.68 %\n",
      "     Overall training accuracy: 88.05 %\n",
      "model 11: SVM RBF Gamma=2.000 C=10.00\n",
      "   Fold 1 accuracy: 81.58 %\n",
      "   Fold 2 accuracy: 81.58 %\n",
      "   Fold 3 accuracy: 85.79 %\n",
      "   Fold 4 accuracy: 79.47 %\n",
      "   Fold 5 accuracy: 83.16 %\n",
      "   Fold 6 accuracy: 83.68 %\n",
      "   Fold 7 accuracy: 83.16 %\n",
      "   Fold 8 accuracy: 84.21 %\n",
      "   Fold 9 accuracy: 88.42 %\n",
      "   Fold 10 accuracy: 80.53 %\n",
      "     Overall test accuracy: 83.16 %\n",
      "     Overall training accuracy: 88.79 %\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# SVM\n",
    "model = 0\n",
    "cont = []\n",
    "results = pd.DataFrame(columns=('name', 'accuracy'))\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "C = [1,2,4,6,8,10]\n",
    "gamma = [1,2]  \n",
    "for g in range(len(gamma)):\n",
    "    acc = []\n",
    "    name = \"SVM RBF Gamma=%.3f\" % (gamma[g])     \n",
    "    for c in range(len(C)):\n",
    "        fold = 1\n",
    "        truth = []\n",
    "        svm_prediction = []\n",
    "        print(\"model %d: SVM RBF Gamma=%.3f C=%.2f\" % (model, gamma[g], C[c]))        \n",
    "        test_count = 0\n",
    "        svm = SVC(C=C[c], kernel='rbf', gamma=gamma[g])\n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            trainX = X[train_idx]\n",
    "            trainY = Y[train_idx]\n",
    "            testX = X[test_idx]\n",
    "            testY = Y[test_idx]\n",
    "            truth.append(testY)\n",
    "            svm.fit(trainX, trainY)\n",
    "            Y_hat = svm.predict(testX)\n",
    "            svm_prediction.append(Y_hat)\n",
    "            print(\"   Fold %d accuracy: %.2f %%\" % (fold, ((np.sum(Y_hat == testY)/len(testY)) * 100.0)))                        \n",
    "            fold += 1\n",
    "        truth = np.concatenate(truth, axis=0)    \n",
    "        svm_prediction = np.concatenate(svm_prediction, axis=0)\n",
    "        test_results = np.sum(svm_prediction == truth)/len(truth)\n",
    "        print(\"     Overall test accuracy: %.2f %%\" % (test_results * 100))  \n",
    "        svm = svm.fit(X, Y)\n",
    "        Y_hat = svm.predict(X)\n",
    "        train_results = np.sum(Y_hat == Y)/len(Y)\n",
    "        print(\"     Overall training accuracy: %.2f %%\" % (train_results * 100.0))  \n",
    "        acc.append([train_results, test_results])   \n",
    "        cont.append([truth, svm_prediction])\n",
    "        model += 1\n",
    "    results = results.append({'name': name, 'accuracy' : acc}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n",
      "vm  0.6448780487804878\n",
      "vn  0.8097560975609757\n",
      "nlp\n",
      "precision:  0.8029556650246306\n",
      "recall:  0.5125786163522013\n",
      "F1:  0.6257197696737045\n",
      "nlp0\n",
      "precision:  0.8114355231143552\n",
      "recall:  0.9434229137199435\n",
      "F1:  0.6257197696737045\n",
      "ave\n",
      "precision:  0.8071955940694928\n",
      "recall:  0.7280007650360724\n",
      "F1:  0.6257197696737045\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(C=10, kernel='rbf', gamma=2) #79.2%\n",
    "#svm = SVC(C=2, kernel='rbf', gamma=128) #79.6\n",
    "#svm = SVC(C=2, kernel='rbf', gamma=128) \n",
    "train_num = 1\n",
    "for i in range(train_num):\n",
    "    svm.fit(X, Y)\n",
    "    Y2_hat = svm.predict(X2)\n",
    "    vm = np.sum(Y2_hat == Ym2)/len(Ym2)\n",
    "    vn = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "    print(np.sum(Y2_hat))\n",
    "    print(\"vm \", vm)\n",
    "    print(\"vn \",vn)\n",
    "    \n",
    "precision = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2)-np.sum(Y2))\n",
    "f10 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp0\")\n",
    "print(\"precision: \", precision0)\n",
    "print(\"recall: \", recall0)\n",
    "print(\"F1: \", f10)\n",
    "\n",
    "print(\"ave\")\n",
    "print(\"precision: \", (precision+precision0)/2)\n",
    "print(\"recall: \", (recall+recall0)/2)\n",
    "print(\"F1: \", (f1+f10)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Best Model: 11\n",
      "\n",
      "SVM\n",
      "          no  social  Total\n",
      "no      1254     252   1506\n",
      "social    68     326    394\n",
      "Total   1322     578   1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "model = input(\"Enter Best Model: \")\n",
    "best = cont[int(model)]\n",
    "rf_ct = pd.crosstab(best[1], best[0], margins=True)\n",
    "rf_ct.columns = [\"no\", \"social\", \"Total\"]\n",
    "rf_ct.index = [\"no\", \"social\", \"Total\"]\n",
    "print()\n",
    "print(\"SVM\")\n",
    "print(rf_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Sensitivity: 0.56401 Specificity: 0.94856 PPV: 0.82741 NPV: 0.83267 Accuracy: 0.83158\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "Sens = rf_ct.iloc[1][1]/rf_ct.iloc[2][1]\n",
    "Spec = rf_ct.iloc[0][0]/rf_ct.iloc[2][0]\n",
    "PPV = rf_ct.iloc[1][1]/rf_ct.iloc[1][2]\n",
    "NPV = rf_ct.iloc[0][0]/rf_ct.iloc[0][2]\n",
    "ACC = (rf_ct.iloc[0][0] + rf_ct.iloc[1][1]) / rf_ct.iloc[2][2]\n",
    "print(\"Random Forest: Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1254   68]\n",
      " [ 252  326]]\n",
      "0.6707818930041152\n",
      "0.5640138408304498\n",
      "0.8274111675126904\n",
      "0.8315789473684211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.95      0.89      1322\n",
      "          1       0.83      0.56      0.67       578\n",
      "\n",
      "avg / total       0.83      0.83      0.82      1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,classification_report\n",
    "y_true =cont[int(model)][0]\n",
    "y_pred = cont[int(model)][1]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred) )\n",
    "\n",
    "print(recall_score(y_true, y_pred),   )\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  0 : Random Forest trees = 5\n",
      "   Fold 1 accuracy: 70.00 %\n",
      "   Fold 2 accuracy: 78.42 %\n",
      "   Fold 3 accuracy: 80.53 %\n",
      "   Fold 4 accuracy: 74.21 %\n",
      "   Fold 5 accuracy: 70.00 %\n",
      "   Fold 6 accuracy: 77.89 %\n",
      "   Fold 7 accuracy: 74.21 %\n",
      "   Fold 8 accuracy: 72.63 %\n",
      "   Fold 9 accuracy: 71.05 %\n",
      "   Fold 10 accuracy: 69.47 %\n",
      "     Overall test accuracy: 73.84 %\n",
      "     Overall training accuracy: 96.95 %\n",
      "model  1 : Random Forest trees = 10\n",
      "   Fold 1 accuracy: 71.58 %\n",
      "   Fold 2 accuracy: 81.58 %\n",
      "   Fold 3 accuracy: 72.11 %\n",
      "   Fold 4 accuracy: 77.37 %\n",
      "   Fold 5 accuracy: 78.42 %\n",
      "   Fold 6 accuracy: 74.21 %\n",
      "   Fold 7 accuracy: 75.79 %\n",
      "   Fold 8 accuracy: 77.89 %\n",
      "   Fold 9 accuracy: 77.37 %\n",
      "   Fold 10 accuracy: 77.89 %\n",
      "     Overall test accuracy: 76.42 %\n",
      "     Overall training accuracy: 98.42 %\n",
      "model  2 : Random Forest trees = 50\n",
      "   Fold 1 accuracy: 76.32 %\n",
      "   Fold 2 accuracy: 78.95 %\n",
      "   Fold 3 accuracy: 76.84 %\n",
      "   Fold 4 accuracy: 80.00 %\n",
      "   Fold 5 accuracy: 76.32 %\n",
      "   Fold 6 accuracy: 77.37 %\n",
      "   Fold 7 accuracy: 76.32 %\n",
      "   Fold 8 accuracy: 77.37 %\n",
      "   Fold 9 accuracy: 77.37 %\n",
      "   Fold 10 accuracy: 82.11 %\n",
      "     Overall test accuracy: 77.89 %\n",
      "     Overall training accuracy: 99.95 %\n",
      "model  3 : Random Forest trees = 100\n",
      "   Fold 1 accuracy: 79.47 %\n",
      "   Fold 2 accuracy: 69.47 %\n",
      "   Fold 3 accuracy: 79.47 %\n",
      "   Fold 4 accuracy: 79.47 %\n",
      "   Fold 5 accuracy: 76.84 %\n",
      "   Fold 6 accuracy: 81.58 %\n",
      "   Fold 7 accuracy: 77.37 %\n",
      "   Fold 8 accuracy: 81.05 %\n",
      "   Fold 9 accuracy: 73.16 %\n",
      "   Fold 10 accuracy: 81.05 %\n",
      "     Overall test accuracy: 77.89 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  4 : Random Forest trees = 200\n",
      "   Fold 1 accuracy: 77.37 %\n",
      "   Fold 2 accuracy: 80.53 %\n",
      "   Fold 3 accuracy: 80.53 %\n",
      "   Fold 4 accuracy: 77.37 %\n",
      "   Fold 5 accuracy: 77.89 %\n",
      "   Fold 6 accuracy: 77.89 %\n",
      "   Fold 7 accuracy: 76.84 %\n",
      "   Fold 8 accuracy: 74.74 %\n",
      "   Fold 9 accuracy: 80.00 %\n",
      "   Fold 10 accuracy: 76.84 %\n",
      "     Overall test accuracy: 78.00 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  5 : Random Forest trees = 300\n",
      "   Fold 1 accuracy: 82.63 %\n",
      "   Fold 2 accuracy: 79.47 %\n",
      "   Fold 3 accuracy: 77.37 %\n",
      "   Fold 4 accuracy: 81.58 %\n",
      "   Fold 5 accuracy: 78.42 %\n",
      "   Fold 6 accuracy: 75.79 %\n",
      "   Fold 7 accuracy: 77.89 %\n",
      "   Fold 8 accuracy: 81.58 %\n",
      "   Fold 9 accuracy: 78.42 %\n",
      "   Fold 10 accuracy: 73.68 %\n",
      "     Overall test accuracy: 78.68 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  6 : Random Forest trees = 400\n",
      "   Fold 1 accuracy: 81.05 %\n",
      "   Fold 2 accuracy: 78.42 %\n",
      "   Fold 3 accuracy: 74.21 %\n",
      "   Fold 4 accuracy: 76.84 %\n",
      "   Fold 5 accuracy: 77.37 %\n",
      "   Fold 6 accuracy: 80.00 %\n",
      "   Fold 7 accuracy: 78.95 %\n",
      "   Fold 8 accuracy: 76.32 %\n",
      "   Fold 9 accuracy: 79.47 %\n",
      "   Fold 10 accuracy: 77.37 %\n",
      "     Overall test accuracy: 78.00 %\n",
      "     Overall training accuracy: 100.00 %\n",
      "model  7 : Random Forest trees = 500\n",
      "   Fold 1 accuracy: 78.95 %\n",
      "   Fold 2 accuracy: 81.58 %\n",
      "   Fold 3 accuracy: 77.89 %\n",
      "   Fold 4 accuracy: 75.79 %\n",
      "   Fold 5 accuracy: 79.47 %\n",
      "   Fold 6 accuracy: 79.47 %\n",
      "   Fold 7 accuracy: 77.89 %\n",
      "   Fold 8 accuracy: 84.74 %\n",
      "   Fold 9 accuracy: 75.26 %\n",
      "   Fold 10 accuracy: 76.84 %\n",
      "     Overall test accuracy: 78.79 %\n",
      "     Overall training accuracy: 100.00 %\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# RandomForest\n",
    "model=0\n",
    "results = []\n",
    "cont = []\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "trees = [5, 10, 50, 100, 200, 300, 400, 500]\n",
    "for t in range(len(trees)):\n",
    "    fold = 1\n",
    "    truth = []\n",
    "    rf_prediction = []\n",
    "    print(\"model \", t, \": Random Forest trees = \" + str(trees[t]))\n",
    "    test_count = 0\n",
    "    rf = RandomForestClassifier(n_estimators=trees[t], criterion='entropy', n_jobs=-1, )\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        trainX = X[train_idx]\n",
    "        trainY = Y[train_idx]\n",
    "        testX = X[test_idx]\n",
    "        testY = Y[test_idx]\n",
    "        truth.append(testY)\n",
    "        rf.fit(trainX, trainY)\n",
    "        Y_hat = rf.predict(testX)\n",
    "        rf_prediction.append(Y_hat)\n",
    "        print(\"   Fold %d accuracy: %.2f %%\" % (fold, ((np.sum(Y_hat == testY)/len(testY)) * 100.0)))                        \n",
    "        fold += 1\n",
    "    truth = np.concatenate(truth, axis=0)    \n",
    "    rf_prediction = np.concatenate(rf_prediction, axis=0)\n",
    "    test_results = np.sum(rf_prediction == truth)/len(truth)\n",
    "    print(\"     Overall test accuracy: %.2f %%\" % (test_results * 100))  \n",
    "    rf = rf.fit(X, Y)\n",
    "    Y_hat = rf.predict(X)\n",
    "    train_results = np.sum(Y_hat == Y)/len(Y)\n",
    "    print(\"     Overall training accuracy: %.2f %%\" % (train_results * 100.0))  \n",
    "    results.append([train_results, test_results])   \n",
    "    cont.append([truth, rf_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n",
      "vm  0.6429268292682927\n",
      "vn  0.7629268292682927\n",
      "nlp\n",
      "precision:  0.7516778523489933\n",
      "recall:  0.3522012578616352\n",
      "F1:  0.4796573875802998\n",
      "nlp0\n",
      "precision:  0.7648401826484018\n",
      "recall:  0.9476661951909476\n",
      "F1:  0.4796573875802998\n",
      "ave\n",
      "precision:  0.7582590174986976\n",
      "recall:  0.6499337265262914\n",
      "F1:  0.4796573875802998\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=500, criterion='entropy', n_jobs=-1, )\n",
    "train_num = 1\n",
    "for i in range(train_num):\n",
    "    rf.fit(X, Y)\n",
    "    Y2_hat = rf.predict(X2)\n",
    "    vm = np.sum(Y2_hat == Ym2)/len(Ym2)\n",
    "    vn = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "    print(np.sum(Y2_hat))\n",
    "    print(\"vm \", vm)\n",
    "    print(\"vn \",vn)\n",
    "    \n",
    "precision = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2_hat)\n",
    "recall = np.sum(Y2_hat + Y2 == 2)/np.sum(Y2)\n",
    "f1 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp\")\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"F1: \", f1)\n",
    "\n",
    "precision0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2_hat)-np.sum(Y2_hat))\n",
    "recall0 = np.sum(Y2_hat + Y2 == 0)/(len(Y2)-np.sum(Y2))\n",
    "f10 = 2*precision*recall/(precision+recall)\n",
    "print(\"nlp0\")\n",
    "print(\"precision: \", precision0)\n",
    "print(\"recall: \", recall0)\n",
    "print(\"F1: \", f10)\n",
    "\n",
    "print(\"ave\")\n",
    "print(\"precision: \", (precision+precision0)/2)\n",
    "print(\"recall: \", (recall+recall0)/2)\n",
    "print(\"F1: \", (f1+f10)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Best Model: 7\n",
      "\n",
      "Random Forest\n",
      "          no  social  Total\n",
      "no      1240     321   1561\n",
      "social    82     257    339\n",
      "Total   1322     578   1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "model = input(\"Enter Best Model: \")\n",
    "best = cont[int(model)]\n",
    "rf_ct = pd.crosstab(best[1], best[0], margins=True)\n",
    "rf_ct.columns = [\"no\", \"social\", \"Total\"]\n",
    "rf_ct.index = [\"no\", \"social\", \"Total\"]\n",
    "print()\n",
    "print(\"Random Forest\")\n",
    "print(rf_ct)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: Sensitivity: 0.44464 Specificity: 0.93797 PPV: 0.75811 NPV: 0.79436 Accuracy: 0.78789\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "Sens = rf_ct.iloc[1][1]/rf_ct.iloc[2][1]\n",
    "Spec = rf_ct.iloc[0][0]/rf_ct.iloc[2][0]\n",
    "PPV = rf_ct.iloc[1][1]/rf_ct.iloc[1][2]\n",
    "NPV = rf_ct.iloc[0][0]/rf_ct.iloc[0][2]\n",
    "ACC = (rf_ct.iloc[0][0] + rf_ct.iloc[1][1]) / rf_ct.iloc[2][2]\n",
    "print(\"Random Forest: Sensitivity: %.5f Specificity: %.5f PPV: %.5f NPV: %.5f Accuracy: %.5f\" % (Sens, Spec, PPV, NPV, ACC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1240   82]\n",
      " [ 321  257]]\n",
      "0.5605234460196292\n",
      "0.444636678200692\n",
      "0.7581120943952803\n",
      "0.7878947368421053\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.94      0.86      1322\n",
      "          1       0.76      0.44      0.56       578\n",
      "\n",
      "avg / total       0.78      0.79      0.77      1900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,classification_report\n",
    "y_true =cont[int(model)][0]\n",
    "y_pred = cont[int(model)][1]\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(f1_score(y_true, y_pred) )\n",
    "\n",
    "\n",
    "\n",
    "print(recall_score(y_true, y_pred),   )\n",
    "print(precision_score(y_true, y_pred))\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.976974\n",
      "Test set score: 0.834211\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "from sklearn.utils import shuffle\n",
    "X, Y = shuffle(X, Y)\n",
    "split = int(len(Y) * 4/5)\n",
    "trainX = X[:split, :]\n",
    "trainY = Y[:split]\n",
    "testX = X[split:, :]\n",
    "testY = Y[split:]\n",
    "\n",
    "#%%\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, alpha=1e-4,\n",
    "                    solver='adam', verbose=False, tol=1e-4, random_state=1)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=10, alpha=1e-4,\n",
    "#                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "#                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(trainX, trainY)\n",
    "print(\"Training set score: %f\" % mlp.score(trainX, trainY))\n",
    "print(\"Test set score: %f\" % mlp.score(testX, testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n",
      "vm  0.6360975609756098\n",
      "vn  0.8263414634146341\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, Y = shuffle(X, Y)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,),max_iter=500, alpha=1e-4)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(100,),max_iter=1000, alpha=1e-4) 67.5%\n",
    "mlp.fit(X,Y)\n",
    "\n",
    "Y2_hat = mlp.predict(X2)\n",
    "vm = np.sum(Y2_hat == Ym2)/len(Ym2)\n",
    "vn = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "print(np.sum(Y2_hat))\n",
    "print(\"vm \", vm)\n",
    "print(\"vn \",vn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n",
      "vm  0.6390243902439025\n",
      "vn  0.8273170731707317\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, Y = shuffle(X, Y)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(300,),max_iter=500, alpha=1e-4)\n",
    "#mlp = MLPClassifier(hidden_layer_sizes=(100,),max_iter=1000, alpha=1e-4) 67.5%\n",
    "mlp.fit(X,Y)\n",
    "\n",
    "Y2_hat = mlp.predict(X2)\n",
    "vm = np.sum(Y2_hat == Ym2)/len(Ym2)\n",
    "vn = np.sum(Y2_hat == Y2)/len(Y2)\n",
    "print(np.sum(Y2_hat))\n",
    "print(\"vm \", vm)\n",
    "print(\"vn \",vn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
